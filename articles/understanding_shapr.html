<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>`shapr`: Explaining individual machine learning predictions with Shapley values • shapr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="`shapr`: Explaining individual machine learning predictions with Shapley values">
<meta property="og:description" content="shapr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">shapr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.2.3.9100</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Vignettes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/understanding_shapr.html">Explaining individual machine learning predictions with Shapley values</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li>
  <a href="../reference/index.html">Manual</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/NorskRegnesentral/shapr/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>
<code>shapr</code>: Explaining individual
machine learning predictions with Shapley values</h1>
                        <h4 data-toc-skip class="author">Camilla
Lingjærde, Martin Jullum, Lars Henry Berge Olsen &amp; Nikolai
Sellereite</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/NorskRegnesentral/shapr/blob/HEAD/vignettes/understanding_shapr.Rmd" class="external-link"><code>vignettes/understanding_shapr.Rmd</code></a></small>
      <div class="hidden name"><code>understanding_shapr.Rmd</code></div>

    </div>

    
    
<blockquote>
<p><a href="#intro">Introduction</a></p>
</blockquote>
<blockquote>
<p><a href="#overview">Overview of Package</a></p>
</blockquote>
<blockquote>
<p><a href="#KSHAP">The Kernel SHAP Method</a></p>
</blockquote>
<blockquote>
<p><a href="#ex">Examples</a></p>
</blockquote>
<blockquote>
<p><a href="#advanced">Advanced usage</a></p>
</blockquote>
<blockquote>
<p><a href="#scalability">Scalability and efficency</a></p>
</blockquote>
<blockquote>
<p><a href="#compare">Comparison to Lundberg &amp; Lee’s
implementation</a></p>
</blockquote>
<p><a id="intro"></a></p>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The <code>shapr</code> package implements an extended version of the
Kernel SHAP method for approximating Shapley values (<span class="citation">Lundberg and Lee (2017)</span>), in which dependence
between the features is taken into account (<span class="citation">Aas,
Jullum, and Løland (2021)</span>). Estimation of Shapley values is of
interest when attempting to explain complex machine learning models. Of
existing work on interpreting individual predictions, Shapley values is
regarded to be the only model-agnostic explanation method with a solid
theoretical foundation (<span class="citation">Lundberg and Lee
(2017)</span>). Kernel SHAP is a computationally efficient approximation
to Shapley values in higher dimensions, but it assumes independent
features. <span class="citation">Aas, Jullum, and Løland (2021)</span>
extend the Kernel SHAP method to handle dependent features, resulting in
more accurate approximations to the true Shapley values. See the <a href="https://www.sciencedirect.com/sdfe/reader/pii/S0004370221000539/pdf" class="external-link">paper</a>
(<span class="citation">Aas, Jullum, and Løland (2021)</span>) for
further details.</p>
<p><a id="overview"></a></p>
<p><br></p>
</div>
<div class="section level2">
<h2 id="overview-of-package">Overview of Package<a class="anchor" aria-label="anchor" href="#overview-of-package"></a>
</h2>
<div class="section level3">
<h3 id="functions">Functions<a class="anchor" aria-label="anchor" href="#functions"></a>
</h3>
<p>Here is an overview of the main functions. You can read their
documentation and see examples with <code>?function_name</code>.</p>
<table class="table">
<caption>Main functions in the <code>shapr</code> package.</caption>
<colgroup>
<col width="30%">
<col width="69%">
</colgroup>
<thead><tr class="header">
<th align="left">Function Name</th>
<th align="left">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>explain</code></td>
<td align="left">Computes kernel SHAP values for test data.</td>
</tr>
<tr class="even">
<td align="left"><code>explain_forecast</code></td>
<td align="left">Analogous to <code>explain</code>, but for explaining
forecasts from time series models.</td>
</tr>
<tr class="odd">
<td align="left"><code>plot.shapr</code></td>
<td align="left">Plots the individual prediction explanations. Uses the
<code>ggplot</code> and <code>ggbeeswarm</code> package.</td>
</tr>
</tbody>
</table>
<p><a id="KSHAP"></a></p>
<p><br></p>
</div>
</div>
<div class="section level2">
<h2 id="the-kernel-shap-method">The Kernel SHAP Method<a class="anchor" aria-label="anchor" href="#the-kernel-shap-method"></a>
</h2>
<p>Assume a predictive model <span class="math inline">\(f(\boldsymbol{x})\)</span> for a response value
<span class="math inline">\(y\)</span> with features <span class="math inline">\(\boldsymbol{x}\in \mathbb{R}^M\)</span>, trained
on a training set, and that we want to explain the predictions for new
sets of data. This may be done using ideas from cooperative game theory,
letting a single prediction take the place of the game being played and
the features the place of the players. Letting <span class="math inline">\(N\)</span> denote the set of all <span class="math inline">\(M\)</span> players, and <span class="math inline">\(S \subseteq N\)</span> be a subset of <span class="math inline">\(|S|\)</span> players, the “contribution” function
<span class="math inline">\(v(S)\)</span> describes the total expected
sum of payoffs the members of <span class="math inline">\(S\)</span> can
obtain by cooperation. The Shapley value (<span class="citation">Shapley
(1953)</span>) is one way to distribute the total gains to the players,
assuming that they all collaborate. The amount that player <span class="math inline">\(i\)</span> gets is then</p>
<p><span class="math display">\[\phi_i(v) = \phi_i = \sum_{S \subseteq N
\setminus\{i\}} \frac{|S| ! (M-| S| - 1)!}{M!}(v(S\cup
\{i\})-v(S)),\]</span></p>
<p>that is, a weighted mean over all subsets <span class="math inline">\(S\)</span> of players not containing player <span class="math inline">\(i\)</span>. <span class="citation">Lundberg and
Lee (2017)</span> define the contribution function for a certain subset
<span class="math inline">\(S\)</span> of these features <span class="math inline">\(\boldsymbol{x}_S\)</span> as <span class="math inline">\(v(S) =
\mbox{E}[f(\boldsymbol{x})|\boldsymbol{x}_S]\)</span>, the expected
output of the predictive model conditional on the feature values of the
subset. <span class="citation">Lundberg and Lee (2017)</span> names this
type of Shapley values SHAP (SHapley Additive exPlanation) values. Since
the conditional expectations can be written as</p>
<span class="math display">\[\begin{equation}
\label{eq:CondExp}
E[f(\boldsymbol{x})|\boldsymbol{x}_s=\boldsymbol{x}_S^*] =
E[f(\boldsymbol{x}_{\bar{S}},\boldsymbol{x}_S)|\boldsymbol{x}_S=\boldsymbol{x}_S^*]
=
\int
f(\boldsymbol{x}_{\bar{S}},\boldsymbol{x}_S^*)\,p(\boldsymbol{x}_{\bar{S}}|\boldsymbol{x}_S=\boldsymbol{x}_S^*)d\boldsymbol{x}_{\bar{S}},
\end{equation}\]</span>
<p>the conditional distributions <span class="math inline">\(p(\boldsymbol{x}_{\bar{S}}|\boldsymbol{x}_S=\boldsymbol{x}_S^*)\)</span>
are needed to compute the contributions. The Kernel SHAP method of <span class="citation">Lundberg and Lee (2017)</span> assumes feature
independence, so that <span class="math inline">\(p(\boldsymbol{x}_{\bar{S}}|\boldsymbol{x}_S=\boldsymbol{x}_S^*)=p(\boldsymbol{x}_{\bar{S}})\)</span>.
If samples <span class="math inline">\(\boldsymbol{x}_{\bar{S}}^{k},
k=1,\ldots,K\)</span>, from <span class="math inline">\(p(\boldsymbol{x}_{\bar{S}}|\boldsymbol{x}_S=\boldsymbol{x}_S^*)\)</span>
are available, the conditional expectation in above can be approximated
by</p>
<span class="math display">\[\begin{equation}
  v_{\text{KerSHAP}}(S) = \frac{1}{K}\sum_{k=1}^K
f(\boldsymbol{x}_{\bar{S}}^{k},\boldsymbol{x}_S^*).
\end{equation}\]</span>
<p>In Kernel SHAP, <span class="math inline">\(\boldsymbol{x}_{\bar{S}}^{k},
k=1,\ldots,K\)</span> are sampled from the <span class="math inline">\(\bar{S}\)</span>-part of the training data,
<em>independently</em> of <span class="math inline">\(\boldsymbol{x}_{S}\)</span>. This is motivated by
using the training set as the empirical distribution of <span class="math inline">\(\boldsymbol{x}_{\bar{S}}\)</span>, and assuming
that <span class="math inline">\(\boldsymbol{x}_{\bar{S}}\)</span> is
independent of <span class="math inline">\(\boldsymbol{x}_S=\boldsymbol{x}_S^*\)</span>. Due
to the independence assumption, if the features in a given model are
highly dependent, the Kernel SHAP method may give a completely wrong
answer. This can be avoided by estimating the conditional distribution
<span class="math inline">\(p(\boldsymbol{x}_{\bar{S}}|\boldsymbol{x}_S=\boldsymbol{x}_S^*)\)</span>
directly and generating samples from this distribution. With this small
change, the contributions and Shapley values may then be approximated as
in the ordinary Kernel SHAP framework. <span class="citation">Aas,
Jullum, and Løland (2021)</span> propose three different approaches for
estimating the conditional probabilities which are implemented:
<code>empirical</code>, <code>gaussian</code> and <code>copula</code>.
The package also implements the method <code>ctree</code> method from
<span class="citation">Redelmeier, Jullum, and Aas (2020)</span>. The
original <code>independence</code> approach of <span class="citation">Lundberg and Lee (2017)</span> is also available. The
methods may also be combined, such that e.g. one method is used when
conditioning on a small number of features, while another method is used
otherwise.</p>
<p><a id="gaussian"></a></p>
<div class="section level3">
<h3 id="multivariate-gaussian-distribution-approach">Multivariate Gaussian Distribution Approach<a class="anchor" aria-label="anchor" href="#multivariate-gaussian-distribution-approach"></a>
</h3>
<p>The first approach arises from the assumption that the feature vector
<span class="math inline">\(\boldsymbol{x}\)</span> stems from a
multivariate Gaussian distribution with some mean vector <span class="math inline">\(\boldsymbol{\mu}\)</span> and covariance matrix
<span class="math inline">\(\boldsymbol{\Sigma}\)</span>. Under this
assumption, the conditional distribution <span class="math inline">\(p(\boldsymbol{x}_{\bar{\mathcal{S}}}
|\boldsymbol{x}_{\mathcal{S}}=\boldsymbol{x}_{\mathcal{S}}^*)\)</span>
is also multivariate Gaussian<br><span class="math inline">\(\text{N}_{|\bar{\mathcal{S}}|}(\boldsymbol{\mu}_{\bar{\mathcal{S}}|\mathcal{S}},\boldsymbol{\Sigma}_{\bar{\mathcal{S}}|\mathcal{S}})\)</span>,
with analytical expressions for the conditional mean vector <span class="math inline">\(\boldsymbol{\mu}_{\bar{\mathcal{S}}|\mathcal{S}}\)</span>
and covariance matrix <span class="math inline">\(\boldsymbol{\Sigma}_{\bar{\mathcal{S}}|\mathcal{S}}\)</span>,
see <span class="citation">Aas, Jullum, and Løland (2021)</span> for
details. Hence, instead of sampling from the marginal empirical
distribution of <span class="math inline">\(\boldsymbol{x}_{\bar{\mathcal{S}}}\)</span>
approximated by the training data, we can sample from the Gaussian
conditional distribution, which is fitted using the training data. Using
the resulting samples <span class="math inline">\(\boldsymbol{x}_{\bar{\mathcal{S}}}^k,
k=1,\ldots,K\)</span>, the conditional expectations be approximated as
in the Kernel SHAP.</p>
<p><a id="copula"></a></p>
</div>
<div class="section level3">
<h3 id="gaussian-copula-approach">Gaussian Copula Approach<a class="anchor" aria-label="anchor" href="#gaussian-copula-approach"></a>
</h3>
<p>If the features are far from multivariate Gaussian, an alternative
approach is to instead represent the marginals by their empirical
distributions, and model the dependence structure by a Gaussian copula.
Assuming a Gaussian copula, we may convert the marginals of the training
data to Gaussian features using their empirical distributions, and then
fit a multivariate Gaussian distribution to these.</p>
<p>To produce samples from the conditional distribution <span class="math inline">\(p(\boldsymbol{x}_{\bar{\mathcal{S}}}
|\boldsymbol{x}_{\mathcal{S}}=\boldsymbol{x}_{\mathcal{S}}^*)\)</span>,
we convert the marginals of <span class="math inline">\(\boldsymbol{x}_{\mathcal{S}}\)</span> to
Gaussians, sample from the conditional Gaussian distribution as above,
and convert the marginals of the samples back to the original
distribution. Those samples are then used to approximate the sample from
the resulting multivariate Gaussian conditional distribution. While
other copulas may be used, the Gaussian copula has the benefit that we
may use the analytical expressions for the conditionals <span class="math inline">\(\boldsymbol{\mu}_{\bar{\mathcal{S}}|\mathcal{S}}\)</span>
and <span class="math inline">\(\boldsymbol{\Sigma}_{\bar{\mathcal{S}}|\mathcal{S}}\)</span>.
Finally, we may convert the marginals back to their original
distribution, and use the resulting samples to approximate the
conditional expectations as in the Kernel SHAP.</p>
<p><a id="empirical"></a></p>
</div>
<div class="section level3">
<h3 id="empirical-conditional-distribution-approach">Empirical Conditional Distribution Approach<a class="anchor" aria-label="anchor" href="#empirical-conditional-distribution-approach"></a>
</h3>
<p>If both the dependence structure and the marginal distributions of
<span class="math inline">\(\boldsymbol{x}\)</span> are very far from
the Gaussian, neither of the two aforementioned methods will work very
well. Few methods exists for the non-parametric estimation of
conditional densities, and the classic kernel estimator (<span class="citation">Rosenblatt (1956)</span>) for non-parametric density
estimation suffers greatly from the curse of dimensionality and does not
provide a way to generate samples from the estimated distribution. For
such situations, <span class="citation">Aas, Jullum, and Løland
(2021)</span> propose an empirical conditional approach to sample
approximately from <span class="math inline">\(p(\boldsymbol{x}_{\bar{\mathcal{S}}}|\boldsymbol{x}_{\mathcal{S}}^*)\)</span>.
The idea is to compute weights <span class="math inline">\(w_{\mathcal{S}}(\boldsymbol{x}^*,\boldsymbol{x}^i),\
i=1,...,n_{\text{train}}\)</span> for all training instances based on
their Mahalanobis distances (in the <span class="math inline">\(S\)</span> subset only) to the instance <span class="math inline">\(\boldsymbol{x}^*\)</span> to be explained. Instead
of sampling from this weighted (conditional) empirical distribution,
<span class="citation">Aas, Jullum, and Løland (2021)</span> suggests a
more efficient variant, using only the <span class="math inline">\(K\)</span> instances with the largest weights:</p>
<p><span class="math display">\[v_{\text{condKerSHAP}}(\mathcal{S}) =
\frac{\sum_{k=1}^K w_{\mathcal{S}}(\boldsymbol{x}^*,
\boldsymbol{x}^{[k]}) f(\boldsymbol{x}_{\bar{\mathcal{S}}}^{[k]},
\boldsymbol{x}_{\mathcal{S}}^*)}{\sum_{k=1}^K
w_{\mathcal{S}}(\boldsymbol{x}^*,\boldsymbol{x}^{[k]})},\]</span></p>
<p>The number of samples <span class="math inline">\(K\)</span> to be
used in the approximate prediction can for instance be chosen such that
the <span class="math inline">\(K\)</span> largest weights accounts for
a fraction <span class="math inline">\(\eta\)</span>, for example <span class="math inline">\(0.9\)</span>, of the total weight. If <span class="math inline">\(K\)</span> exceeds a certain limit, for instance
<span class="math inline">\(5,000\)</span>, it might be set to that
limit. A bandwidth parameter <span class="math inline">\(\sigma\)</span>
used to scale the weights, must also be specified. This choice may be
viewed as a bias-variance trade-off. A small <span class="math inline">\(\sigma\)</span> puts most of the weight to a few
of the closest training observations and thereby gives low bias, but
high variance. When <span class="math inline">\(\sigma \rightarrow
\infty\)</span>, this method converges to the original Kernel SHAP
assuming feature independence. Typically, when the features are highly
dependent, a small <span class="math inline">\(\sigma\)</span> is
typically needed such that the bias does not dominate. <span class="citation">Aas, Jullum, and Løland (2021)</span> show that a
proper criterion for selecting <span class="math inline">\(\sigma\)</span> is a small-sample-size corrected
version of the AIC known as AICc. As calculation of it is
computationally intensive, an approximate version of the selection
criterion is also suggested. Details on this is found in <span class="citation">Aas, Jullum, and Løland (2021)</span>.</p>
<p><a id="ex"></a></p>
<p><br></p>
</div>
<div class="section level3">
<h3 id="conditional-inference-tree-approach">Conditional Inference Tree Approach<a class="anchor" aria-label="anchor" href="#conditional-inference-tree-approach"></a>
</h3>
<p>The previous three methods can only handle numerical data. This means
that if the data contains categorical/discrete/ordinal features, the
features first have to be one-hot encoded. When the number of
levels/features is large, this is not feasible. An approach that handles
mixed (i.e numerical, categorical, discrete, ordinal) features and both
univariate and multivariate responses is conditional inference trees
(<span class="citation">Hothorn, Hornik, and Zeileis (2006)</span>).</p>
<p>Conditional inference trees is a special tree fitting procedure that
relies on hypothesis tests to choose both the splitting feature and the
splitting point. The tree fitting procedure is sequential: first a
splitting feature is chosen (the feature that is least independent of
the response), and then a splitting point is chosen for this feature.
This decreases the chance of being biased towards features with many
splits (<span class="citation">Hothorn, Hornik, and Zeileis
(2006)</span>).</p>
<p>We use conditional inference trees (<em>ctree</em>) to model the
conditional distribution, <span class="math inline">\(p(\boldsymbol{x}_{\bar{\mathcal{S}}}|\boldsymbol{x}_{\mathcal{S}}^*)\)</span>,
found in the Shapley methodology. First, we fit a different conditional
inference tree to each conditional distribution. Once a tree is fit for
given dependent features, the end node of <span class="math inline">\(\boldsymbol{x}_{\mathcal{S}}^*\)</span> is found.
Then, we sample from this end node and use the resulting samples, <span class="math inline">\(\boldsymbol{x}_{\bar{\mathcal{S}}}^k,
k=1,\ldots,K\)</span>, when approximating the conditional expectations
as in Kernel SHAP. See <span class="citation">Redelmeier, Jullum, and
Aas (2020)</span> for more details.</p>
<p>The conditional inference trees are fit using the <em>party</em> and
<em>partykit</em> packages (<span class="citation">Hothorn and Zeileis
(2015)</span>).</p>
</div>
<div class="section level3">
<h3 id="categorical-approach">Categorical Approach<a class="anchor" aria-label="anchor" href="#categorical-approach"></a>
</h3>
<p>When the features are all categorical, we can estimate the
conditional expectations using basic statistical formulas. For example,
if we have three features, <span class="math inline">\(x_1, x_2,
x_3\)</span> with three levels each (indicated as 1, 2, 3), and we are
provided with a table of counts indicating how many times each
combination of feature values occurs, we can estimate the marginal and
conditional probabilities as follows. Marginal probabilities are
estimated by dividing the number of times a given feature (or features)
takes on a certain value in the data set with the total number of
observations in the data set. Condititional probabilities (for example,
<span class="math inline">\(P(X_1 = 1 | X_2 = 1)\)</span>) are estimated
by first subsetting the data set to reflect the conditioning (i.e.,
extracting all rows where <span class="math inline">\(X_2 = 1\)</span>),
and then dividing the number of times the feature on the left hand side
of <span class="math inline">\(|\)</span> takes the given value in this
subset by the total number of observations in this subset. Once the
marginal and conditional probabilities are estimated for all
combinations of feature values, each conditional expectation can be
calculated. For example, the expected value of <span class="math inline">\(X_1\)</span> given <span class="math inline">\(X_2
= 1\)</span> and <span class="math inline">\(X_3 = 2\)</span> is <span class="math display">\[E(X_1|X_2, X_3) = \sum_{x}x P(X_1 = x | X_2=1,
X_3=2) = \sum_{x} x \frac{P(X_1 = x, X_2 = 1, X_3 = 2)}{P(X_2=1,
X_3=2)}.\]</span>.</p>
<p><a id="ex"></a></p>
<p><br></p>
</div>
</div>
<div class="section level2">
<h2 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h2>
<p><code>shapr</code> supports computation of Shapley values with any
predictive model which takes a set of numeric features and produces a
numeric outcome. Note that the ctree method takes both numeric and
categorical variables. Check under “Advanced usage” for an example of
how this can be done.</p>
<p>The following example shows how a simple <code>xgboost</code> model
is trained using the <code>airquality</code> dataset, and how
<code>shapr</code> can be used to explain the individual predictions.
Note that the empirical conditional distribution approach is the default
(i.e. <code>approach = "empirical"</code>). The Gaussian, Gaussian
copula, ctree or independence approaches can be used instead by setting
the argument <code>approach</code> to either <code>"gaussian"</code>,
<code>"copula"</code>, <code>"ctree"</code>, <code>"categorical"</code>
or <code>"independence"</code> in the code below.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/dmlc/xgboost" class="external-link">xgboost</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://r-datatable.com" class="external-link">data.table</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"airquality"</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/stats/complete.cases.html" class="external-link">complete.cases</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month"</span><span class="op">)</span></span>
<span><span class="va">y_var</span> <span class="op">&lt;-</span> <span class="st">"Ozone"</span></span>
<span></span>
<span><span class="va">ind_x_explain</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="fu"><a href="https://rdrr.io/r/base/get.html" class="external-link">get</a></span><span class="op">(</span><span class="va">y_var</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">x_explain</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fitting a basic xgboost model to the training data</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">xgboost</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span>,</span>
<span>  label <span class="op">=</span> <span class="va">y_train</span>,</span>
<span>  nround <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Specifying the phi_0, i.e. the expected prediction without any features</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Computing the actual Shapley values with kernelSHAP accounting for feature dependence using</span></span>
<span><span class="co"># the empirical (conditional) distribution approach with bandwidth parameter sigma = 0.1 (default)</span></span>
<span><span class="va">explanation</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Printing the Shapley values for the test data.</span></span>
<span><span class="co"># For more information about the interpretation of the values in the table, see ?shapr::explain.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">explanation</span><span class="op">$</span><span class="va">shapley_values</span><span class="op">)</span></span>
<span><span class="co">#&gt;        none    Solar.R      Wind      Temp      Month</span></span>
<span><span class="co">#&gt; 1: 43.08571 13.2117337  4.785645 -25.57222  -5.599230</span></span>
<span><span class="co">#&gt; 2: 43.08571 -9.9727747  5.830694 -11.03873  -7.829954</span></span>
<span><span class="co">#&gt; 3: 43.08571 -2.2916185 -7.053393 -10.15035  -4.452481</span></span>
<span><span class="co">#&gt; 4: 43.08571  3.3254595 -3.240879 -10.22492  -6.663488</span></span>
<span><span class="co">#&gt; 5: 43.08571  4.3039571 -2.627764 -14.15166 -12.266855</span></span>
<span><span class="co">#&gt; 6: 43.08571  0.4786417 -5.248686 -12.55344  -6.645738</span></span>
<span></span>
<span><span class="co"># Plot the resulting explanations for observations 1 and 6</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation</span>, bar_plot_phi0 <span class="op">=</span> <span class="cn">FALSE</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-2-1.png" width="672"></p>
<p>There are multiple plot options specified by the
<code>plot_type</code> argument in <code>plot</code>. The
<code>waterfall</code> option shows the changes in the prediction score
due to each features contribution (their Shapley values):</p>
<p>There are multiple plot options specified by the
<code>plot_type</code> argument in <code>plot</code>. The
<code>waterfall</code> option shows the changes in the prediction score
due to each features contribution (their Shapley values):</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation</span>, plot_type <span class="op">=</span> <span class="st">"waterfall"</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-3-1.png" width="672"></p>
<p>The other two plot options, <code>"beeswarm"</code> and
<code>"scatter"</code>, can be useful when you have many observations
that you want to explain. For the purpose of illustration, we explain
the whole <code>airquality</code> dataset (including the training data)
for these plot types. The <code>plot_type = "beeswarm"</code> summarises
the distribution of the Shapley values along the x-axis across all
features. Each point gives the Shapley value of a given instance, where
the points are colored by the feature value of that instance:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x_explain_many</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span><span class="va">explanation_plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_many</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_plot</span>, plot_type <span class="op">=</span> <span class="st">"beeswarm"</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-4-1.png" width="672"></p>
<p>The <code>plot_type = "scatter"</code> plots the feature values on
the x-axis and Shapley values on the y-axis, as well as (optionally) a
background scatter_hist showing the distribution of the feature
data:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_plot</span>, plot_type <span class="op">=</span> <span class="st">"scatter"</span>, scatter_hist <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-5-1.png" width="672"></p>
<p>We can use mixed (i.e continuous, categorical, ordinal) data with
ctree. Use ctree with mixed data in the following manner:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># convert the month variable to a factor</span></span>
<span><span class="va">data</span><span class="op">[</span>, <span class="va">Month_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">Month</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">data_train_cat</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span><span class="va">data_explain_cat</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">x_var_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R"</span>, <span class="st">"Wind"</span>, <span class="st">"Temp"</span>, <span class="st">"Month_factor"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_train_cat</span> <span class="op">&lt;-</span> <span class="va">data_train_cat</span><span class="op">[</span>, <span class="va">..x_var_cat</span><span class="op">]</span></span>
<span><span class="va">x_explain_cat</span> <span class="op">&lt;-</span> <span class="va">data_explain_cat</span><span class="op">[</span>, <span class="va">..x_var_cat</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fitting an lm model here as xgboost does not handle categorical features directly</span></span>
<span><span class="co"># (work around in example below)</span></span>
<span><span class="va">lm_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">y_var</span>, <span class="st">" ~ "</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">x_var_cat</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_lm_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">lm_formula</span>, <span class="va">data_train_cat</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span><span class="va">explanation_lm_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_lm_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"ctree"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot the resulting explanations for observations 1 and 6, excluding</span></span>
<span><span class="co"># the no-covariate effect</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_lm_cat</span>, bar_plot_phi0 <span class="op">=</span> <span class="cn">FALSE</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-6-1.png" width="672"></p>
<p>We can specify parameters used to build the conditional inference
trees in the following manner. Default values are based on <span class="citation">Hothorn, Hornik, and Zeileis (2006)</span>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Use the conditional inference tree approach</span></span>
<span><span class="co"># We can specify parameters used to building trees by specifying mincriterion,</span></span>
<span><span class="co"># minsplit, minbucket</span></span>
<span><span class="va">explanation_ctree</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_lm_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"ctree"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  ctree.mincriterion <span class="op">=</span> <span class="fl">0.80</span>,</span>
<span>  ctree.minsplit <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  ctree.minbucket <span class="op">=</span> <span class="fl">20</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Default parameters (based on (Hothorn, 2006)) are:</span></span>
<span><span class="co"># mincriterion = 0.95</span></span>
<span><span class="co"># minsplit = 20</span></span>
<span><span class="co"># minbucket = 7</span></span></code></pre></div>
<p>If <strong>all</strong> features are categorical, one may use the
categorical approach as follows:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For the sake of illustration, convert ALL features to factors</span></span>
<span><span class="va">data</span><span class="op">[</span>, <span class="va">Solar.R_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cut.html" class="external-link">cut</a></span><span class="op">(</span><span class="va">Solar.R</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">data</span><span class="op">[</span>, <span class="va">Wind_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cut.html" class="external-link">cut</a></span><span class="op">(</span><span class="va">Wind</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">data</span><span class="op">[</span>, <span class="va">Temp_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cut.html" class="external-link">cut</a></span><span class="op">(</span><span class="va">Temp</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">data</span><span class="op">[</span>, <span class="va">Month_factor</span> <span class="op">:=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">as.factor</a></span><span class="op">(</span><span class="va">Month</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="va">data_train_all_cat</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span><span class="va">data_explain_all_cat</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="op">]</span></span>
<span></span>
<span></span>
<span><span class="va">x_var_all_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Solar.R_factor"</span>, <span class="st">"Wind_factor"</span>, <span class="st">"Temp_factor"</span>, <span class="st">"Month_factor"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_train_all_cat</span> <span class="op">&lt;-</span> <span class="va">data_train_all_cat</span><span class="op">[</span>, <span class="va">..x_var_all_cat</span><span class="op">]</span></span>
<span><span class="va">x_explain_all_cat</span> <span class="op">&lt;-</span> <span class="va">data_explain_all_cat</span><span class="op">[</span>, <span class="va">..x_var_all_cat</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fit an lm model here</span></span>
<span><span class="va">lm_formula_all_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">y_var</span>, <span class="st">" ~ "</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">x_var_all_cat</span>, collapse <span class="op">=</span> <span class="st">" + "</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_lm_all_cat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">lm_formula_all_cat</span>, <span class="va">data_train_all_cat</span><span class="op">)</span></span>
<span></span>
<span><span class="va">explanation_cat_method</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_lm_all_cat</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_all_cat</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_all_cat</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"categorical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Shapley values can be used to explain any predictive model. For
predictive models taking time series as input,
<code>approach='timeseries'</code> can be used. In such models, joint
behavior of consecutive time points is often more important for the
outcome than the single time points. Therefore, it makes sense to derive
Shapley value segments of the time series instead of for each single
time point. In <code>shapr</code> this can be achieved through the
<code>group</code> attribute. Other optional parameters of
<code>approach='timeseries'</code> are
<code>timeseries.fixed_sigma_vec</code> and
<code>timeseries.bounds</code> (a vector indicating upper and lower
bounds of the time series if necessary).</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulate time series data with AR(1)-structure</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">data_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="cn">NA</span>, ncol <span class="op">=</span> <span class="fl">41</span>, nrow <span class="op">=</span> <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">n</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span>
<span>  <span class="va">e</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">42</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">m_1</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">e</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">m_1</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">+</span> <span class="fl">0.8</span> <span class="op">*</span> <span class="va">m_1</span><span class="op">[</span><span class="va">i</span> <span class="op">-</span> <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">e</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">data_ts</span><span class="op">[</span><span class="va">n</span>, <span class="op">]</span> <span class="op">&lt;-</span> <span class="va">m_1</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="op">}</span></span>
<span><span class="va">data_ts</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">data_ts</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_var_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">40</span><span class="op">)</span></span>
<span><span class="va">y_var_ts</span> <span class="op">&lt;-</span> <span class="st">"X41"</span></span>
<span></span>
<span><span class="va">ind_x_explain</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span></span>
<span><span class="va">data_ts_train</span> <span class="op">&lt;-</span> <span class="va">data_ts</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Creating a predictive model (for illustration just predicting the next point in the time series with a linear model)</span></span>
<span><span class="va">lm_ts_formula</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="va">X41</span> <span class="op">~</span> <span class="va">.</span><span class="op">)</span></span>
<span><span class="va">model_lm_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">lm_ts_formula</span>, <span class="va">data_ts_train</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_explain_ts</span> <span class="op">&lt;-</span> <span class="va">data_ts</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="va">..x_var_ts</span><span class="op">]</span></span>
<span><span class="va">x_train_ts</span> <span class="op">&lt;-</span> <span class="va">data_ts</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="va">..x_var_ts</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Spitting the time series into 4 segments</span></span>
<span><span class="va">group_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  S1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span>,</span>
<span>  S2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">11</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span>,</span>
<span>  S3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">21</span><span class="op">:</span><span class="fl">30</span><span class="op">)</span>,</span>
<span>  S4 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="fl">31</span><span class="op">:</span><span class="fl">40</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">p0_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unlist.html" class="external-link">unlist</a></span><span class="op">(</span><span class="va">data_ts_train</span><span class="op">[</span>, <span class="va">..y_var_ts</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">explanation_timeseries</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_lm_ts</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain_ts</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train_ts</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"timeseries"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_ts</span>,</span>
<span>  group <span class="op">=</span> <span class="va">group_ts</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="msev-evaluation-criterion">MSEv evaluation criterion<a class="anchor" aria-label="anchor" href="#msev-evaluation-criterion"></a>
</h3>
<p>We can use the <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion proposed
by <span class="citation">Frye et al. (2021)</span>, and later used by,
e.g., <span class="citation">Olsen et al. (2022)</span> and <span class="citation">Olsen et al. (2023)</span>, to evaluate and rank the
approaches/methods. The <span class="math inline">\(\operatorname{MSE}_{v}\)</span> is given by</p>
<span class="math display">\[\begin{align}
    \label{eq:MSE_v}
    \operatorname{MSE}_{v} = \operatorname{MSE}_{v}(\text{method }
\texttt{q})
    =
     \frac{1}{N_\mathcal{S}} \sum_{\mathcal{S} \in
\mathcal{P}^*(\mathcal{M})} \frac{1}{N_\text{explain}}
     \sum_{i=1}^{N_\text{explain}} \left( f(\boldsymbol{x}^{[i]}) -
{\hat{v}}_{\texttt{q}}(\mathcal{S}, \boldsymbol{x}^{[i]})\right)^2\!,
\end{align}\]</span>
<p>where <span class="math inline">\({\hat{v}}_{\texttt{q}}\)</span> is
the estimated contribution function using method <span class="math inline">\(\texttt{q}\)</span> and <span class="math inline">\(N_\mathcal{S} = |\mathcal{P}^*(\mathcal{M})| =
2^M-2\)</span>, i.e., we have removed the empty (<span class="math inline">\(\mathcal{S} = \emptyset\)</span>) and the grand
combinations (<span class="math inline">\(\mathcal{S} =
\mathcal{M}\)</span>) as they are method independent. Meaning that these
two combinations do not influence the ranking of the methods as the
methods are not used to compute the contribution function for them.</p>
<p>The motivation behind the <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion is that
<span class="math inline">\(\mathbb{E}_\mathcal{S}\mathbb{E}_{\boldsymbol{x}}
(v_{\texttt{true}}(\mathcal{S},\boldsymbol{x}) -
\hat{v}_{\texttt{q}}(\mathcal{S}, \boldsymbol{x}))^2\)</span> can be
decomposed as</p>
<span class="math display">\[\begin{align}
    \label{eq:expectation_decomposition}
    \begin{split}
    \mathbb{E}_\mathcal{S}\mathbb{E}_{\boldsymbol{x}}
(v_{\texttt{true}}(\mathcal{S}, \boldsymbol{x})-
\hat{v}_{\texttt{q}}(\mathcal{S}, \boldsymbol{x}))^2
    &amp;=
    \mathbb{E}_\mathcal{S}\mathbb{E}_{\boldsymbol{x}} (f(\boldsymbol{x})
- \hat{v}_{\texttt{q}}(\mathcal{S}, \boldsymbol{x}))^2 \\
    &amp;\phantom{\,\,\,\,\,\,\,}-
\mathbb{E}_\mathcal{S}\mathbb{E}_{\boldsymbol{x}}
(f(\boldsymbol{x})-v_{\texttt{true}}(\mathcal{S}, \boldsymbol{x}))^2,
    \end{split}
\end{align}\]</span>
<p>see Appendix A in <span class="citation">Covert, Lundberg, and Lee
(2020)</span>. The first term on the right-hand side of the equation
above can be estimated by <span class="math inline">\(\operatorname{MSE}_{v}\)</span>, while the second
term is a fixed (unknown) constant not influenced by the approach .
Thus, a low value of <span class="math inline">\(\operatorname{MSE}_{v}\)</span> indicates that the
estimated contribution function <span class="math inline">\(\hat{v}_{\texttt{q}}\)</span> is closer to the
true counterpart <span class="math inline">\(v_{\texttt{true}}\)</span>
than a high value.</p>
<p>In <code>shapr</code>, we allow for weighting the combinations in the
<span class="math inline">\(\operatorname{MSE}_{v}\)</span> evaluation
criterion either uniformly or by using the corresponding Shapley kernel
weights (or the sampling frequencies when sampling of combinations is
used). This is determined by the logical parameter
<code>MSEv_uniform_comb_weights</code> in the <code><a href="../reference/explain.html">explain()</a></code>
function, and the default is to do uniform weighting, that is,
<code>MSEv_uniform_comb_weights = TRUE</code>.</p>
<div class="section level4">
<h4 id="advantage">Advantage:<a class="anchor" aria-label="anchor" href="#advantage"></a>
</h4>
<p>An advantage of the <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion is that
<span class="math inline">\(v_\texttt{true}\)</span> is not involved.
Thus, we can apply it as an evaluation criterion to real-world data sets
where the true Shapley values are unknown.</p>
</div>
<div class="section level4">
<h4 id="disadvantages">Disadvantages:<a class="anchor" aria-label="anchor" href="#disadvantages"></a>
</h4>
<p>First, we can only use the <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion to rank
the methods and not assess their closeness to the optimum since the
minimum value of the <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion is
unknown. Second, the criterion evaluates the contribution functions and
not the Shapley values.</p>
<p>Note that <span class="citation">Olsen et al. (2023)</span> observed
a relatively linear relationship between the <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion and the
mean absolute error <span class="math inline">\((\operatorname{MAE})\)</span> between the true and
estimated Shapley values in extensive simulation studies where the true
Shapley values were known. That is, a method that achieves a low <span class="math inline">\(\operatorname{MSE}_{v}\)</span> score also tends
to obtain a low <span class="math inline">\(\operatorname{MAE}\)</span>
score, and vice versa.</p>
</div>
<div class="section level4">
<h4 id="confidence-intervals">Confidence intervals<a class="anchor" aria-label="anchor" href="#confidence-intervals"></a>
</h4>
<p>The <span class="math inline">\(\operatorname{MSE}_{v}\)</span>
criterion can be written as <span class="math inline">\(\operatorname{MSE}_{v} =
\frac{1}{N_\text{explain}}\sum_{i=1}^{N_\text{explain}}
\operatorname{MSE}_{v,\text{explain }i}\)</span>. We can therefore use
the central limit theorem to compute an approximate confidence interval
for the <span class="math inline">\(\operatorname{MSE}_{v}\)</span>
criterion. We have that <span class="math inline">\(\operatorname{MSE}_{v} \pm
t_{\alpha/2}\frac{\operatorname{SD}(\operatorname{MSE}_{v})}{\sqrt{N_\text{explain}}}\)</span>
is a <span class="math inline">\((1-\alpha/2)\%\)</span> approximate
confidence interval for the evaluation criterion, where <span class="math inline">\(t_{\alpha/2}\)</span> is the <span class="math inline">\(\alpha/2\)</span> percentile of the <span class="math inline">\(T_{N_\text{explain}-1}\)</span> distribution. Note
that <span class="math inline">\(N_\text{explain}\)</span> should be
large (rule of thumb is at least <span class="math inline">\(30\)</span>) for the central limit theorem to be
valid. The quantities <span class="math inline">\(\operatorname{MSE}_{v}\)</span> and <span class="math inline">\(\frac{\operatorname{SD}(\operatorname{MSE}_{v})}{\sqrt{N_\text{explain}}}\)</span>
are returned by the <code><a href="../reference/explain.html">explain()</a></code> function in the
<code>MSEv</code> list of data tables. We can also compute similar
approximate confidence interval for <span class="math inline">\(\operatorname{MSE}_{v}\)</span> criterion for each
combination/coalition when only averaging over the observations.
However, it does not make sense in the other direction, i.e., when only
averaging over the combinations for each observation, as each
combination is a different prediction tasks.</p>
</div>
<div class="section level4">
<h4 id="msev-examples">MSEv examples<a class="anchor" aria-label="anchor" href="#msev-examples"></a>
</h4>
<p>Start by explaining the predictions by using different methods and
combining them into lists.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We use more explicands here for more stable confidence intervals</span></span>
<span><span class="va">ind_x_explain</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">25</span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span><span class="va">y_train</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="va">ind_x_explain</span>, <span class="fu"><a href="https://rdrr.io/r/base/get.html" class="external-link">get</a></span><span class="op">(</span><span class="va">y_var</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">x_explain</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="va">ind_x_explain</span>, <span class="va">..x_var</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Fitting a basic xgboost model to the training data</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">xgboost</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span>,</span>
<span>  label <span class="op">=</span> <span class="va">y_train</span>,</span>
<span>  nround <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Specifying the phi_0, i.e. the expected prediction without any features</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Independence approach</span></span>
<span><span class="va">explanation_independence</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"independence"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">1e2</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  MSEv_uniform_comb_weights <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Empirical approach</span></span>
<span><span class="va">explanation_empirical</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">1e2</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  MSEv_uniform_comb_weights <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Gaussian 1e1 approach</span></span>
<span><span class="va">explanation_gaussian_1e1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"gaussian"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">1e1</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  MSEv_uniform_comb_weights <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Gaussian 1e2 approach</span></span>
<span><span class="va">explanation_gaussian_1e2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"gaussian"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">1e2</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  MSEv_uniform_comb_weights <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Combined approach</span></span>
<span><span class="va">explanation_combined</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"gaussian"</span>, <span class="st">"empirical"</span>, <span class="st">"independence"</span><span class="op">)</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_samples <span class="op">=</span> <span class="fl">1e2</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  MSEv_uniform_comb_weights <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a list of explanations with names</span></span>
<span><span class="va">explanation_list_named</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="st">"Ind."</span> <span class="op">=</span> <span class="va">explanation_independence</span>,</span>
<span>  <span class="st">"Emp."</span> <span class="op">=</span> <span class="va">explanation_empirical</span>,</span>
<span>  <span class="st">"Gaus. 1e1"</span> <span class="op">=</span> <span class="va">explanation_gaussian_1e1</span>,</span>
<span>  <span class="st">"Gaus. 1e2"</span> <span class="op">=</span> <span class="va">explanation_gaussian_1e2</span>,</span>
<span>  <span class="st">"Combined"</span> <span class="op">=</span> <span class="va">explanation_combined</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can then compare the different approaches by creating plots of the
<span class="math inline">\(\operatorname{MSE}_{v}\)</span> evaluation
criterion.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create the MSEv plots with approximate 95% confidence intervals</span></span>
<span><span class="va">MSEv_plots</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit</a></span><span class="op">(</span><span class="va">explanation_list_named</span>,</span>
<span>  plot_type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"overall"</span>, <span class="st">"comb"</span>, <span class="st">"explicand"</span><span class="op">)</span>,</span>
<span>  CI_level <span class="op">=</span> <span class="fl">0.95</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 5 plots are made</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">MSEv_plots</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "MSEv_explicand_bar"          "MSEv_explicand_line_point"  </span></span>
<span><span class="co">#&gt; [3] "MSEv_combination_bar"        "MSEv_combination_line_point"</span></span>
<span><span class="co">#&gt; [5] "MSEv_bar"</span></span></code></pre></div>
<p>The main plot if interest is the <code>MSEv_bar</code>, which
displays the <span class="math inline">\(\operatorname{MSE}_{v}\)</span>
evaluation criterion for each method averaged over both the
combinations/coalitions and test observations/explicands. However, we
can also look at the other plots where we have only averaged over the
observations or the combinations (both as bar and line plots).</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The main plot of the overall MSEv averaged over both the combinations and observations</span></span>
<span><span class="va">MSEv_plots</span><span class="op">$</span><span class="va">MSEv_bar</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-12-1.png" width="672"></p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># The MSEv averaged over only the explicands for each combinations</span></span>
<span><span class="va">MSEv_plots</span><span class="op">$</span><span class="va">MSEv_combination_bar</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-12-2.png" width="672"></p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># The MSEv averaged over only the combinations for each observation/explicand</span></span>
<span><span class="va">MSEv_plots</span><span class="op">$</span><span class="va">MSEv_explicand_bar</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-12-3.png" width="672"></p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="co"># To see which coalition S each of the `id_combination` corresponds to,</span></span>
<span><span class="co"># i.e., which features that are conditions on.</span></span>
<span><span class="va">explanation_list_named</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="va">MSEv</span><span class="op">$</span><span class="va">MSEv_combination</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"id_combination"</span>, <span class="st">"features"</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="co">#&gt;     id_combination features</span></span>
<span><span class="co">#&gt;  1:              2        1</span></span>
<span><span class="co">#&gt;  2:              3        2</span></span>
<span><span class="co">#&gt;  3:              4        3</span></span>
<span><span class="co">#&gt;  4:              5        4</span></span>
<span><span class="co">#&gt;  5:              6      1,2</span></span>
<span><span class="co">#&gt;  6:              7      1,3</span></span>
<span><span class="co">#&gt;  7:              8      1,4</span></span>
<span><span class="co">#&gt;  8:              9      2,3</span></span>
<span><span class="co">#&gt;  9:             10      2,4</span></span>
<span><span class="co">#&gt; 10:             11      3,4</span></span>
<span><span class="co">#&gt; 11:             12    1,2,3</span></span>
<span><span class="co">#&gt; 12:             13    1,2,4</span></span>
<span><span class="co">#&gt; 13:             14    1,3,4</span></span>
<span><span class="co">#&gt; 14:             15    2,3,4</span></span></code></pre></div>
<p>We can specify the <code>index_x_explain</code> and
<code>id_combination</code> parameters in
<code><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit()</a></code> to only plot certain test
observations and combinations, respectively.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We can specify which test observations or combinations to plot</span></span>
<span><span class="fu"><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit</a></span><span class="op">(</span><span class="va">explanation_list_named</span>,</span>
<span>  plot_type <span class="op">=</span> <span class="st">"explicand"</span>,</span>
<span>  index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span>, <span class="fl">6</span><span class="op">)</span>,</span>
<span>  CI_level <span class="op">=</span> <span class="fl">0.95</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">MSEv_explicand_bar</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-13-1.png" width="672"></p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit</a></span><span class="op">(</span><span class="va">explanation_list_named</span>,</span>
<span>  plot_type <span class="op">=</span> <span class="st">"comb"</span>,</span>
<span>  id_combination <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">9</span>, <span class="fl">13</span><span class="op">:</span><span class="fl">15</span><span class="op">)</span>,</span>
<span>  CI_level <span class="op">=</span> <span class="fl">0.95</span></span>
<span><span class="op">)</span><span class="op">$</span><span class="va">MSEv_combination_bar</span></span>
<span><span class="co">#&gt; NULL</span></span></code></pre></div>
<p>We can also alter the plots design-wise as we do in the code
below.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bar_text_n_decimals</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">CI_level</span> <span class="op">&lt;-</span> <span class="fl">0.95</span></span>
<span><span class="va">MSEv_plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/plot_MSEv_eval_crit.html">plot_MSEv_eval_crit</a></span><span class="op">(</span><span class="va">explanation_list_named</span>, CI_level <span class="op">=</span> <span class="va">CI_level</span><span class="op">)</span><span class="op">$</span><span class="va">MSEv_bar</span></span>
<span><span class="va">MSEv_plot</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_discrete.html" class="external-link">scale_x_discrete</a></span><span class="op">(</span>limits <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/levels.html" class="external-link">levels</a></span><span class="op">(</span><span class="va">MSEv_plot</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">Method</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html" class="external-link">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_brewer.html" class="external-link">scale_fill_brewer</a></span><span class="op">(</span>palette <span class="op">=</span> <span class="st">"Paired"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="co"># This must be set before other theme calls</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span></span>
<span>    plot.title <span class="op">=</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html" class="external-link">element_text</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>,</span>
<span>    legend.position <span class="op">=</span> <span class="st">"bottom"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html" class="external-link">geom_text</a></span><span class="op">(</span></span>
<span>    <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span></span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"%."</span>, <span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"%d"</span>, <span class="va">bar_text_n_decimals</span><span class="op">)</span>, <span class="st">"f"</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">MSEv</span>, <span class="va">bar_text_n_decimals</span><span class="op">)</span></span>
<span>    <span class="op">)</span><span class="op">)</span>,</span>
<span>    vjust <span class="op">=</span> <span class="op">-</span><span class="fl">0.35</span>, <span class="co"># This number might need altering for different plots sizes</span></span>
<span>    hjust <span class="op">=</span> <span class="fl">1.1</span>, <span class="co"># This number might need altering for different plots sizes</span></span>
<span>    color <span class="op">=</span> <span class="st">"black"</span>,</span>
<span>    position <span class="op">=</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/position_dodge.html" class="external-link">position_dodge</a></span><span class="op">(</span><span class="fl">0.9</span><span class="op">)</span>,</span>
<span>    size <span class="op">=</span> <span class="fl">4</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-14-1.png" width="672"></p>
</div>
</div>
<div class="section level3">
<h3 id="main-arguments-in-explain">Main arguments in <code>explain</code><a class="anchor" aria-label="anchor" href="#main-arguments-in-explain"></a>
</h3>
<p>When using <code>explain</code>, the default behavior is to use all
feature combinations in the Shapley formula. Kernel SHAP’s sampling
based approach may be used by specifying <code>n_combinations</code>,
which is the number of unique feature combinations to sample. If not
specified, the exact method is used. The computation time grows
approximately exponentially with the number of features. The training
data and the model whose predictions we wish to explain must be provided
through the arguments <code>x_train</code> and <code>model</code>. The
data whose predicted values we wish to explain must be given by the
argument <code>x_explain</code>. Note that both <code>x_train</code> and
<code>x_explain</code> must be a <code>data.frame</code> or a
<code>matrix</code>, and all elements must be finite numerical values.
Currently we do not support missing values. The default approach when
computing the Shapley values is the empirical approach
(i.e. <code>approach = "empirical"</code>). If you’d like to use a
different approach you’ll need to set <code>approach</code> equal to
either <code>copula</code> or <code>gaussian</code>, or a vector of
them, with length equal to the number of features. If a vector, a
combined approach is used, and element <code>i</code> indicates the
approach to use when conditioning on <code>i</code> variables. For more
details see <a href="#combined">Combined approach</a> below.</p>
<p>When computing the kernel SHAP values by <code>explain</code>, the
maximum number of samples to use in the Monte Carlo integration for
every conditional expectation is controlled by the argument
<code>n_samples</code> (default equals <code>1000</code>). The
computation time grows approximately linear with this number. You will
also need to pass a numeric value for the argument
<code>prediction_zero</code>, which represents the prediction value when
not conditioning on any features. We recommend setting this equal to the
mean of the response, but other values, like the mean prediction of a
large test data set is also a possibility. If the empirical method is
used, specific settings for that approach, like a vector of fixed <span class="math inline">\(\sigma\)</span> values can be specified through
the argument <code>empirical.fixed_sigma</code>. See
<code><a href="../reference/explain.html">?explain</a></code> for more information. If
<code>approach = "gaussian"</code>, you may specify the mean vector and
covariance matrix of the data generating distribution by the arguments
<code>gaussian.mu</code> and <code>gaussian.cov_mat</code>. If not
specified, they are estimated from the training data.</p>
</div>
<div class="section level3">
<h3 id="explaining-a-forecasting-model-using-explain_forecast">Explaining a forecasting model using
<code>explain_forecast</code><a class="anchor" aria-label="anchor" href="#explaining-a-forecasting-model-using-explain_forecast"></a>
</h3>
<p><code>shapr</code> provides a specific function,
<code>explain_forecast</code>, to explain forecasts from time series
models, at one or more steps into the future. The main difference
compared to <code>explain</code> is that the data is supplied as (set
of) time series, in addition to index arguments (<code>train_idx</code>
and <code>explain_idx</code>) specifying which time points that
represents the train and explain parts of the data. See
<code><a href="../reference/explain_forecast.html">?explain_forecast</a></code> for more information.</p>
<p>To demonstrate how to use the function, 500 observations are
generated which follow an AR(1) structure, i.e. <span class="math inline">\(y_t = 0.5 y_{t-1} + \varepsilon_t\)</span>. To
this data an arima model of order (2, 0, 0) is fitted, and we therefore
would like to explain the forecasts in terms of the two previous lags of
the time series. This is is specified through the argument
<code>explain_y_lags = 2</code>. Note that some models may also put
restrictions on the amount of data required to make a forecast. The
AR(2) model we used there, for instance, requires two previous time
point to make a forecast.</p>
<p>In the example, two separate forecasts, each three steps ahead, are
explained. To set the starting points of the two forecasts,
<code>explain_idx</code> is set to <code>499:500</code>. This means that
one forecast of <span class="math inline">\(t = (500, 501, 502)\)</span>
and another of <span class="math inline">\(t = (501, 502, 503)\)</span>,
will be explained. In other words, <code>explain_idx</code> tells
<code>shapr</code> at which points in time data was available up until,
when making the forecast to explain.</p>
<p>In the same way, <code>train_idx</code> denotes the points in time
used to estimate the conditional expectations used to explain the
different forecasts. Note that since we want to explain the forecasts in
terms of the two previous lags (<code>explain_y_lags = 2</code>), the
smallest value of <code>train_idx</code> must also be 2, because at time
<span class="math inline">\(t = 1\)</span> there was only a single
observation available.</p>
<p>Since the data is stationary, the mean of the data is used as value
of <code>prediction_zero</code> (i.e. <span class="math inline">\(\phi_0\)</span>). This can however be chosen
differently depending on the data and application.</p>
<p>For a multivariate model such as a VAR (Vector AutoRegressive model),
it may be of more interesting to explain the impact of each variable,
rather than each lag of each variable. This can be done by setting
<code>group_lags = TRUE</code>.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Simulate time series data with AR(1)-structure.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">data_ts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>Y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.sim.html" class="external-link">arima.sim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>, ar <span class="op">=</span> <span class="fl">.5</span><span class="op">)</span>, n <span class="op">=</span> <span class="fl">500</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data_ts</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">data_ts</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit an ARIMA(2, 0, 0) model.</span></span>
<span><span class="va">arima_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.html" class="external-link">arima</a></span><span class="op">(</span><span class="va">data_ts</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set prediction zero as the mean of the data for each forecast point.</span></span>
<span><span class="va">p0_ar</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data_ts</span><span class="op">$</span><span class="va">Y</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Explain forecasts from points t = 499 and t = 500.</span></span>
<span><span class="va">explain_idx</span> <span class="op">&lt;-</span> <span class="fl">499</span><span class="op">:</span><span class="fl">500</span></span>
<span></span>
<span><span class="va">explanation_forecast</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain_forecast.html">explain_forecast</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">arima_model</span>,</span>
<span>  y <span class="op">=</span> <span class="va">data_ts</span>,</span>
<span>  train_idx <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">498</span>,</span>
<span>  explain_idx <span class="op">=</span> <span class="fl">499</span><span class="op">:</span><span class="fl">500</span>,</span>
<span>  explain_y_lags <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  horizon <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0_ar</span>,</span>
<span>  group_lags <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">explanation_forecast</span></span>
<span><span class="co">#&gt;    explain_idx horizon    none     Y.1      Y.2</span></span>
<span><span class="co">#&gt; 1:         499       1 0.04018  0.5053 -0.07659</span></span>
<span><span class="co">#&gt; 2:         500       1 0.04018 -0.3622  0.02497</span></span>
<span><span class="co">#&gt; 3:         499       2 0.04018  0.5053 -0.07659</span></span>
<span><span class="co">#&gt; 4:         500       2 0.04018 -0.3622  0.02497</span></span>
<span><span class="co">#&gt; 5:         499       3 0.04018  0.5053 -0.07659</span></span>
<span><span class="co">#&gt; 6:         500       3 0.04018 -0.3622  0.02497</span></span></code></pre></div>
<p>Note that for a multivariate model such as a VAR (Vector
AutoRegressive model), or for models also including several exogenous
variables, it may be of more informative to explain the impact of each
variable, rather than each lag of each variable. This can be done by
setting <code>group_lags = TRUE</code>. This does not make sense for
this model, however, as that would result in decomposing the forecast
into a single group.</p>
<p>We now give a more hands on example of how to use the
<code>explain_forecast</code> function. Say that we have an AR(2) model
which describes the change over time of the variable <code>Temp</code>
in the dataset <code>airquality</code>. It seems reasonable to assume
that the temperature today should affect the temperature tomorrow. To a
lesser extent, we may also suggest that the temperature today should
also have an impact on that of the day after tomorrow.</p>
<p>We start by building our AR(2) model, naming it
<code>model_ar_temp</code>. This model is then used to make a forecast
of the temperature of the day that comes after the last day in the data,
this forecast starts from index 153.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span></span>
<span></span>
<span><span class="va">model_ar_temp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ar.html" class="external-link">ar</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">Temp</span>, order <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model_ar_temp</span>, n.ahead <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">$</span><span class="va">pred</span></span>
<span><span class="co">#&gt; Time Series:</span></span>
<span><span class="co">#&gt; Start = 154 </span></span>
<span><span class="co">#&gt; End = 155 </span></span>
<span><span class="co">#&gt; Frequency = 1 </span></span>
<span><span class="co">#&gt; [1] 71.08111 71.52445</span></span></code></pre></div>
<p>First, we pass the model and the data as <code>model</code> and
<code>y</code>. Since we have an AR(2) model, we want to explain the
forecasts in terms of the two previous lags, whihc we specify with
<code>explain_y_lags = 2</code>. Then, we let <code>shapr</code> know
which time indices to use as training data through the argument
<code>train_idx</code>. We use <code>2:152</code>, meaning that we skip
the first index, as we want to explain the two previous lags. Letting
the training indices go up until 152 means that every point in time
except the first and last will be used as training data.</p>
<p>The last index, 153 is passed as the argument
<code>explain_idx</code>, which means that we want to explain a forecast
made from time point 153 in the data. The argument <code>horizon</code>
is set to 2 in order to explain a forecast of length 2.</p>
<p>The argument <code>prediction_zero</code> is set to the mean of the
time series, and is repeated two times. Each value of
<code>prediction_zero</code> is the baseline for each forecast horizon.
In our example, we assume that given no effect from the two lags, the
temperature would just be the average during the observed period.
Finally, we opt to not group the lags by setting <code>group_lags</code>
to <code>FALSE</code>. This means that lag 1 and 2 will be explained
separately. Grouping lags may be more interesting to do in a model with
multiple variables, as it is then possible to explain each variable
separately.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain_forecast.html">explain_forecast</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_ar_temp</span>,</span>
<span>  y <span class="op">=</span> <span class="va">data</span><span class="op">[</span>, <span class="st">"Temp"</span><span class="op">]</span>,</span>
<span>  train_idx <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">152</span>,</span>
<span>  explain_idx <span class="op">=</span> <span class="fl">153</span>,</span>
<span>  explain_y_lags <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  horizon <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">Temp</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>  group_lags <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  timing <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">explanation</span><span class="op">)</span></span>
<span><span class="co">#&gt;    explain_idx horizon  none Temp.1  Temp.2</span></span>
<span><span class="co">#&gt; 1:         153       1 77.88 -6.622 -0.1788</span></span>
<span><span class="co">#&gt; 2:         153       2 77.88 -6.025 -0.3327</span></span></code></pre></div>
<p>The results are presented per value of <code>explain_idx</code> and
forecast horizon. We can see that the mean temperature was around 77.9
degrees. At horizon 1, the first lag in the model caused it to be 6.6
degrees lower, and the second lag had just a minor effect. At horizon 2,
the first lag has a slightly smaller negative impact, and the second lag
has a slightly larger impact.</p>
<p>It is also possible to explain a forecasting model which uses
exogenous regressors. The previous example is expanded to use an
ARIMA(2,0,0) model with <code>Wind</code> as an exogenous regressor.
Since the exogenous regressor must be available for the predicted time
points, the model is just fit on the 151 first observations, leaving two
observations of <code>Wind</code> to be used as exogenous values during
the prediction phase.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">data.table</span><span class="fu">::</span><span class="fu"><a href="https://rdatatable.gitlab.io/data.table/reference/as.data.table.html" class="external-link">as.data.table</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">)</span></span>
<span></span>
<span><span class="va">data_fit</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="fl">151</span><span class="op">)</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">model_arimax_temp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/arima.html" class="external-link">arima</a></span><span class="op">(</span><span class="va">data_fit</span><span class="op">$</span><span class="va">Temp</span>, order <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">0</span>, <span class="fl">0</span><span class="op">)</span>, xreg <span class="op">=</span> <span class="va">data_fit</span><span class="op">$</span><span class="va">Wind</span><span class="op">)</span></span>
<span></span>
<span><span class="va">newxreg</span> <span class="op">&lt;-</span> <span class="va">data</span><span class="op">[</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_len</a></span><span class="op">(</span><span class="fl">151</span><span class="op">)</span>, <span class="st">"Wind"</span>, drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model_arimax_temp</span>, n.ahead <span class="op">=</span> <span class="fl">2</span>, newxreg <span class="op">=</span> <span class="va">newxreg</span><span class="op">)</span><span class="op">$</span><span class="va">pred</span></span>
<span><span class="co">#&gt; Time Series:</span></span>
<span><span class="co">#&gt; Start = 152 </span></span>
<span><span class="co">#&gt; End = 153 </span></span>
<span><span class="co">#&gt; Frequency = 1 </span></span>
<span><span class="co">#&gt; [1] 77.49992 76.38062</span></span></code></pre></div>
<p>The <code>shapr</code> package can then explain not only the two
autoregressive lags, but also the single lag of the exogenous regressor.
In order to do so, the <code>Wind</code> variable is passed as the
argument <code>xreg</code>, and <code>explain_xreg_lags</code> is set to
1. Notice how only the first 151 observations are used for
<code>y</code> and all 153 are used for <code>xreg</code>. This makes it
possible for <code>shapr</code> to not only explain the effect of the
first lag of the exogenous variable, but also the contemporary effect
during the forecasting period.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain_forecast.html">explain_forecast</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_ar_temp</span>,</span>
<span>  y <span class="op">=</span> <span class="va">data_fit</span><span class="op">[</span>, <span class="st">"Temp"</span><span class="op">]</span>,</span>
<span>  xreg <span class="op">=</span> <span class="va">data</span><span class="op">[</span>, <span class="st">"Wind"</span><span class="op">]</span>,</span>
<span>  train_idx <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">150</span>,</span>
<span>  explain_idx <span class="op">=</span> <span class="fl">151</span>,</span>
<span>  explain_y_lags <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  explain_xreg_lags <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  horizon <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data_fit</span><span class="op">$</span><span class="va">Temp</span><span class="op">)</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>  group_lags <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  timing <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">explanation</span><span class="op">$</span><span class="va">shapley_values</span><span class="op">)</span></span>
<span><span class="co">#&gt;    explain_idx horizon     none     Temp.1     Temp.2    Wind.1   Wind.F1</span></span>
<span><span class="co">#&gt; 1:         151       1 77.96026 -0.6779272 -0.6734041 -1.268789 0.4934084</span></span>
<span><span class="co">#&gt; 2:         151       2 77.96026  0.3996832 -0.5005937 -1.465464 0.0659129</span></span>
<span><span class="co">#&gt;       Wind.F2</span></span>
<span><span class="co">#&gt; 1:         NA</span></span>
<span><span class="co">#&gt; 2: -0.4742238</span></span></code></pre></div>
<p><a id="advanced"></a></p>
<p><br></p>
</div>
</div>
<div class="section level2">
<h2 id="advanced-usage">Advanced usage<a class="anchor" aria-label="anchor" href="#advanced-usage"></a>
</h2>
<p><a id="combined"></a></p>
<div class="section level3">
<h3 id="combined-approach">Combined approach<a class="anchor" aria-label="anchor" href="#combined-approach"></a>
</h3>
<p>In addition to letting the user select one of the five aforementioned
approaches for estimating the conditional distribution of the data (i.e.
<code>approach</code> equals either <a href="#gaussian"><code>"gaussian"</code></a>, <a href="#copula"><code>"copula"</code></a>, <a href="#empirical"><code>"empirical"</code></a>, <a href="#ctree"><code>"ctree"</code></a>, <a href="#categorical"><code>"categorical"</code></a>) or
<code>"timeseries"</code>, the package allows the user to combine the
given approaches. To simplify the usage, the flexibility is restricted
such that the same approach is used when conditioning on the same number
of features. This is also in line <span class="citation">Aas, Jullum,
and Løland (2021, sec. 3.4)</span>.</p>
<p>This can be done by setting <code>approach</code> equal to a
character vector, where the length of the vector is one less than the
number of features in the model. Consider a situation where you have
trained a model that consists of 10 features, and you would like to use
the <code>"empirical"</code> approach when you condition on 1-3
features, the <code>"copula"</code> approach when you condition on 4-5
features, and the <code>"gaussian"</code> approach when conditioning on
6 or more features. This can be applied by simply passing
<code>approach = c(rep("empirical", 3), rep("copula", 2), rep("gaussian", 4))</code>,
i.e. <code>approach[i]</code> determines which method to use when
conditioning on <code>i</code> features. Conditioning on all features
needs no approach as that is given by the complete prediction itself,
and should thus not be part of the vector.</p>
<p>The code below exemplifies this approach for a case where there are
four features, using <code>"empirical", "copula"</code> and
<code>"gaussian"</code> when conditioning on respectively 1, 2 and 3
features.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Use the combined approach</span></span>
<span><span class="va">explanation_combined</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"empirical"</span>, <span class="st">"copula"</span>, <span class="st">"gaussian"</span><span class="op">)</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Plot the resulting explanations for observations 1 and 6, excluding</span></span>
<span><span class="co"># the no-covariate effect</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_combined</span>, bar_plot_phi0 <span class="op">=</span> <span class="cn">FALSE</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-20-1.png" width="672"></p>
<p>As a second example using <code>"ctree"</code> to conditin on 1 and 2
features, and <code>"empirical"</code> when conditioning on 3
features:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Use the combined approach</span></span>
<span><span class="va">explanation_combined</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"ctree"</span>, <span class="st">"ctree"</span>, <span class="st">"empirical"</span><span class="op">)</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="explain-groups-of-features">Explain groups of features<a class="anchor" aria-label="anchor" href="#explain-groups-of-features"></a>
</h3>
<p>In some cases, especially when the number of features is very large,
it may be more appropriate to explain predictions in terms of groups of
features instead of single features, see (<span class="citation">Jullum,
Redelmeier, and Aas (2021)</span>) for intuition and real world
examples. Explaining prediction in terms of groups of features is very
easy using <code>shapr</code>:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define the feature groups</span></span>
<span><span class="va">group_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  A <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Temp"</span>, <span class="st">"Month"</span><span class="op">)</span>,</span>
<span>  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Wind"</span>, <span class="st">"Solar.R"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use the empirical approach</span></span>
<span><span class="va">explanation_group</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  group <span class="op">=</span> <span class="va">group_list</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Prints the group-wise explanations</span></span>
<span><span class="va">explanation_group</span></span>
<span><span class="co">#&gt;      none       A        B</span></span>
<span><span class="co">#&gt;  1: 47.27 -29.588  13.1628</span></span>
<span><span class="co">#&gt;  2: 47.27 -11.834 -15.7011</span></span>
<span><span class="co">#&gt;  3: 47.27 -15.976 -17.5729</span></span>
<span><span class="co">#&gt;  4: 47.27 -25.067  -5.1374</span></span>
<span><span class="co">#&gt;  5: 47.27 -35.848  20.2892</span></span>
<span><span class="co">#&gt;  6: 47.27 -27.257  -8.4830</span></span>
<span><span class="co">#&gt;  7: 47.27 -14.960 -21.3995</span></span>
<span><span class="co">#&gt;  8: 47.27 -18.325   7.3791</span></span>
<span><span class="co">#&gt;  9: 47.27 -23.012   9.6591</span></span>
<span><span class="co">#&gt; 10: 47.27 -16.189  -5.6100</span></span>
<span><span class="co">#&gt; 11: 47.27 -25.607 -10.1334</span></span>
<span><span class="co">#&gt; 12: 47.27 -25.065  -5.1394</span></span>
<span><span class="co">#&gt; 13: 47.27 -25.841  -0.7281</span></span>
<span><span class="co">#&gt; 14: 47.27 -21.518 -13.3293</span></span>
<span><span class="co">#&gt; 15: 47.27 -21.248  -1.3199</span></span>
<span><span class="co">#&gt; 16: 47.27 -13.676 -16.9497</span></span>
<span><span class="co">#&gt; 17: 47.27 -13.899 -14.8890</span></span>
<span><span class="co">#&gt; 18: 47.27 -12.276  -8.2472</span></span>
<span><span class="co">#&gt; 19: 47.27 -13.768 -13.5242</span></span>
<span><span class="co">#&gt; 20: 47.27 -24.866 -10.8744</span></span>
<span><span class="co">#&gt; 21: 47.27 -14.486 -22.7674</span></span>
<span><span class="co">#&gt; 22: 47.27  -4.122 -14.2893</span></span>
<span><span class="co">#&gt; 23: 47.27 -11.218  22.4682</span></span>
<span><span class="co">#&gt; 24: 47.27 -33.002  14.2114</span></span>
<span><span class="co">#&gt; 25: 47.27 -16.251  -8.6796</span></span>
<span><span class="co">#&gt;      none       A        B</span></span>
<span><span class="co"># Plots the group-wise explanations</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_group</span>, bar_plot_phi0 <span class="op">=</span> <span class="cn">TRUE</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-22-1.png" width="672"></p>
</div>
<div class="section level3">
<h3 id="explain-custom-models">Explain custom models<a class="anchor" aria-label="anchor" href="#explain-custom-models"></a>
</h3>
<p><code>shapr</code> currently natively supports explanation of
predictions from models fitted with the following functions:</p>
<ul>
<li><code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">stats::lm</a></code></li>
<li><code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">stats::glm</a></code></li>
<li><code><a href="http://imbs-hl.github.io/ranger/reference/ranger.html" class="external-link">ranger::ranger</a></code></li>
<li><code><a href="https://rdrr.io/pkg/mgcv/man/gam.html" class="external-link">mgcv::gam</a></code></li>
<li>
<code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost::xgboost</a></code>/<code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html" class="external-link">xgboost::xgb.train</a></code>
</li>
</ul>
<p>Any continuous response regression model or binary classification
model of these model classes, can be explained with the package directly
as exemplified above. Moreover, essentially any feature dependent
prediction model can be explained by the package by specifying two (or
one) simple additional functions for your model.</p>
<p><em>Note: The below procedure for specifying custom models was
changed in shapr v0.3.0</em> The first function is
<code>predict_model</code>, taking the model and data (as a
<code>matrix</code> or <code>data.frame/data.table</code>) as input and
outputting the corresponding prediction as a numeric vector. The second
(optional, but highly recommended) function is
<code>get_model_specs</code>, taking the model as input and outputting a
list with the following elements: <em>labels</em> (vector with the
feature names to compute Shapley values for), <em>classes</em> (a named
vector with the labels as names and the class type as elements),
<em>factor_levels</em> (a named list with the labels as names and
vectors with the factor levels as elements (NULL if the feature is not a
factor)). The <code>get_model_specs</code> function is used to check
that the format of the data passed to <code>explain</code> have the
correct format in terms of the necessary feature columns being available
and having the correct class/attributes. It is highly recommended to do
such checks in order to ensure correct usage of <code>explain</code>.
If, for some reason, such checking is not desirable, one does not have
to provide the <code>get_model_specs</code> function. This will,
however, throw a warning that all feature consistency checking against
the model is disabled.</p>
<p>Once the above functions are created, you can explain predictions
from this model as before by passing the functions through the input
arguments <code>predict_model</code> and <code>get_model_specs</code> of
<code><a href="../reference/explain.html">explain()</a></code>.</p>
<p>These functions <strong>can</strong> be made general enough to handle
all supported model types of that class, or they can be made minimal,
possibly only allowing explanation of the specific version of the model
class at hand. Below we give examples of both full support versions of
these functions and a minimal version which skips the
<code>get_model_specs</code> function. We do this for the
<code>gbm</code> model class from the <code>gbm</code> package, fitted
to the same airquality data set as used above.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/gbm-developers/gbm" class="external-link">gbm</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loaded gbm 2.1.9</span></span>
<span><span class="co">#&gt; This version of gbm is no longer under development. Consider transitioning to gbm3, https://github.com/gbm-developers/gbm3</span></span>
<span></span>
<span><span class="va">formula_gbm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/formula.html" class="external-link">as.formula</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">y_var</span>, <span class="st">"~"</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">x_var</span>, collapse <span class="op">=</span> <span class="st">"+"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Fitting a gbm model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">825</span><span class="op">)</span></span>
<span><span class="va">model_gbm</span> <span class="op">&lt;-</span> <span class="fu">gbm</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/gbm/man/gbm.html" class="external-link">gbm</a></span><span class="op">(</span></span>
<span>  <span class="va">formula_gbm</span>,</span>
<span>  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">x_train</span>, Ozone <span class="op">=</span> <span class="va">y_train</span><span class="op">)</span>,</span>
<span>  distribution <span class="op">=</span> <span class="st">"gaussian"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co">#### Full feature versions of the three required model functions ####</span></span>
<span><span class="va">MY_predict_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">newdata</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"gbm"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="kw"><a href="https://rdrr.io/r/base/stop.html" class="external-link">stop</a></span><span class="op">(</span><span class="st">"The gbm package is required for predicting train models"</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="va">model_type</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span></span>
<span>    <span class="va">x</span><span class="op">$</span><span class="va">distribution</span><span class="op">$</span><span class="va">name</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"bernoulli"</span>, <span class="st">"adaboost"</span><span class="op">)</span>,</span>
<span>    <span class="st">"classification"</span>,</span>
<span>    <span class="st">"regression"</span></span>
<span>  <span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">model_type</span> <span class="op">==</span> <span class="st">"classification"</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">newdata</span><span class="op">)</span>, type <span class="op">=</span> <span class="st">"response"</span>, n.trees <span class="op">=</span> <span class="va">x</span><span class="op">$</span><span class="va">n.trees</span><span class="op">)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">newdata</span><span class="op">)</span>, n.trees <span class="op">=</span> <span class="va">x</span><span class="op">$</span><span class="va">n.trees</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span></span>
<span><span class="va">MY_get_model_specs</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">feature_specs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">feature_specs</span><span class="op">$</span><span class="va">labels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/labels.html" class="external-link">labels</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Terms</span><span class="op">)</span></span>
<span>  <span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">feature_specs</span><span class="op">$</span><span class="va">labels</span><span class="op">)</span></span>
<span>  <span class="va">feature_specs</span><span class="op">$</span><span class="va">classes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">x</span><span class="op">$</span><span class="va">Terms</span>, <span class="st">"dataClasses"</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">feature_specs</span><span class="op">$</span><span class="va">factor_levels</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/setNames.html" class="external-link">setNames</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">vector</a></span><span class="op">(</span><span class="st">"list"</span>, <span class="va">m</span><span class="op">)</span>, <span class="va">feature_specs</span><span class="op">$</span><span class="va">labels</span><span class="op">)</span></span>
<span>  <span class="va">feature_specs</span><span class="op">$</span><span class="va">factor_levels</span><span class="op">[</span><span class="va">feature_specs</span><span class="op">$</span><span class="va">classes</span> <span class="op">==</span> <span class="st">"factor"</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span> <span class="co"># model object doesn't contain factor levels info</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">feature_specs</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Compute the Shapley values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span></span>
<span><span class="va">explanation_custom</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_gbm</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  predict_model <span class="op">=</span> <span class="va">MY_predict_model</span>,</span>
<span>  get_model_specs <span class="op">=</span> <span class="va">MY_get_model_specs</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Setting parameter 'n_batches' to 2 as a fair trade-off between memory consumption and computation time.</span></span>
<span><span class="co">#&gt; Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span></span>
<span></span>
<span><span class="co"># Plot results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_custom</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-23-1.png" width="672"></p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span></span>
<span><span class="co">#### Minimal version of the three required model functions ####</span></span>
<span><span class="co"># Note: Working only for this exact version of the model class</span></span>
<span><span class="co"># Avoiding to define get_model_specs skips all feature</span></span>
<span><span class="co"># consistency checking between your data and model</span></span>
<span><span class="va">MY_MINIMAL_predict_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">newdata</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">newdata</span><span class="op">)</span>, n.trees <span class="op">=</span> <span class="va">x</span><span class="op">$</span><span class="va">n.trees</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># Compute the Shapley values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">explanation_custom_minimal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model_gbm</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  predict_model <span class="op">=</span> <span class="va">MY_MINIMAL_predict_model</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Note: You passed a model to explain() which is not natively supported, and did not supply a 'get_model_specs' function to explain().</span></span>
<span><span class="co">#&gt; Consistency checks between model and data is therefore disabled.</span></span>
<span><span class="co">#&gt; Setting parameter 'n_batches' to 2 as a fair trade-off between memory consumption and computation time.</span></span>
<span><span class="co">#&gt; Reducing 'n_batches' typically reduces the computation time at the cost of increased memory consumption.</span></span>
<span></span>
<span><span class="co"># Plot results</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">explanation_custom_minimal</span>, index_x_explain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="understanding_shapr_files/figure-html/unnamed-chunk-23-2.png" width="672"></p>
<p><a id="scalability"></a></p>
<p><br></p>
</div>
</div>
<div class="section level2">
<h2 id="scalability-and-efficency">Scalability and efficency<a class="anchor" aria-label="anchor" href="#scalability-and-efficency"></a>
</h2>
<div class="section level3">
<h3 id="batch-computation">Batch computation<a class="anchor" aria-label="anchor" href="#batch-computation"></a>
</h3>
<p>The computational complexity of Shapley value based explanations
grows fast in the number of features, as the number of conditional
expectations one needs to estimate in the Shapley formula grows
exponentially. As outlined <a href="#KSHAP">above</a>, the estimating of
each of these conditional expectations is also computationally
expensive, typically requiring estimation of a conditional probability
distribution, followed by Monte Carlo integration. These computations
are not only heavy for the CPU, they also require a lot of memory (RAM),
which typically is a limited resource. By doing the most resource hungry
computations (the computation of v(S)) in sequential batches with
different feature subsets <span class="math inline">\(S\)</span>, the
memory usage can be significantly reduces. Such batching comes at the
cost of an increase in computation time, which depends on the number of
feature subsets (<code>n_combinations</code>), the number of features,
the estimation <code>approach</code> and so on. When calling
<code><a href="../reference/explain.html">shapr::explain()</a></code>, we allow the user to set the number of
batches with the argument <code>n_batches</code>. The default of this
argument is <code>NULL</code>, which uses a (hopefully) reasonable
trade-off between computation speed and memory consumption which depends
on <code>n_combinations</code> and <code>approach</code>. The
memory/computation time trade-off is most apparent for models with more
than say 6-7 features. Below we a basic example where
<code>n_batches=10</code>:</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">explanation_batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="parallelized-computation">Parallelized computation<a class="anchor" aria-label="anchor" href="#parallelized-computation"></a>
</h3>
<p>In addition to reducing the memory consumption, the introduction of
the <code>n_batch</code> argument allows computation within each batch
to be performed in parallel. The parallelization in
<code><a href="../reference/explain.html">shapr::explain()</a></code> is handled by the
<code>future_apply</code> which builds on the <code>future</code>
environment. The <code>future</code> package works on all OS, allows the
user to decide the parallelization backend (mutliple R procesess or
forking), works directly with hpc clusters, and also supports progress
updates for the parallelized task (see below).</p>
<p>Note that, since it takes some time to duplicate data into different
processes/machines when running in parallel, it is not always
preferrable to run <code><a href="../reference/explain.html">shapr::explain()</a></code> in parallel, at least
not with many parallel sessions (hereby called
<strong>workers</strong>). Parallelizatiob also increases the memory
consumption proportionally, so you want to limit the number of workers
for that reason too. In a future version of <code>shapr</code> we will
provide experienced based automatic selection of the number of workers.
In the meanwhile, this is all lef to the user, and we advice that
<code>n_batches</code> equals some positive integer multiplied by the
number of workers. Below is a basic example of a parallelization with
two workers.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://future.futureverse.org" class="external-link">future</a></span><span class="op">)</span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">multisession</span>, workers <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="va">explanation_par</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">future</span><span class="fu">::</span><span class="fu"><a href="https://future.futureverse.org/reference/plan.html" class="external-link">plan</a></span><span class="op">(</span><span class="va">sequential</span><span class="op">)</span> <span class="co"># To return to non-parallel computation</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="progress-updates">Progress updates<a class="anchor" aria-label="anchor" href="#progress-updates"></a>
</h3>
<p><code>shapr</code> provides progress updates of the computation of
the Shapley values through the R-package <code>progressr</code>. This
gives the user full control over the visual apperance of the progress
updates, and also intergrates seemlessly with the parallelization
framework <code>future</code> used by <code>shapr</code> (see above).
Note that the progress is updated as the batches are completed, meaning
that if you have choosen <code>n_batches=1</code>, you will not get
intermediate updates, while if you set <code>n_batches=10</code> you
will get updates on every 10% of the computation.</p>
<p>Progress updates are enabled for the current R-session by running the
command <code>progressr::handlers(local=TRUE)</code>, before calling
<code><a href="../reference/explain.html">shapr::explain()</a></code>. To use progress updates for only a single
call to <code><a href="../reference/explain.html">shapr::explain()</a></code>, one can wrap the call using
<code><a href="https://progressr.futureverse.org/reference/with_progress.html" class="external-link">progressr::with_progress</a></code> as follows:
<code>progressr::with_progress({ shapr::explain() })</code> The default
appearence of the progress updates is a basic ASCII-based horizontal
progress bar. Other variants can be chosen by passing different strings
to <code><a href="https://progressr.futureverse.org/reference/handlers.html" class="external-link">progressr::handlers()</a></code>, some of which require additional
packages. If you are using Rstudio, the progress can be displayed
directly in the gui with <code>progressr::handlers('rstudio')</code>
(requires the <code>rstudioapi</code> package). If you are running
Windows, you may use the pop-up gui progress bar
<code>progressr::handlers('handler_winprogressbar')</code>. A wrapper
for progressbar of the flexible <code>cli</code> package is also
available <code>progressr::handlers('cli')</code> (requires the
<code>cli</code> package).</p>
<p>For a full list of all progression handlers and the customization
options available with <code>progressr</code>, see the
<code>progressr</code> <a href="https://cran.r-project.org/web/packages/progressr/vignettes/progressr-intro.html" class="external-link">vignette</a>.
A full code example of using <code>progressr</code> with
<code>shapr</code> is shown below:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://progressr.futureverse.org" class="external-link">progressr</a></span><span class="op">)</span></span>
<span><span class="fu">progressr</span><span class="fu">::</span><span class="fu"><a href="https://progressr.futureverse.org/reference/handlers.html" class="external-link">handlers</a></span><span class="op">(</span>global <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co"># If no progression handler is specified, the txtprogressbar is used</span></span>
<span><span class="co"># Other progression handlers:</span></span>
<span><span class="co"># progressr::handlers('rstudio') # requires the 'rstudioapi' package</span></span>
<span><span class="co"># progressr::handlers('handler_winprogressbar') # Window only</span></span>
<span><span class="co"># progressr::handlers('cli') # requires the 'cli' package</span></span>
<span><span class="va">explanation</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span></span>
<span>  model <span class="op">=</span> <span class="va">model</span>,</span>
<span>  x_explain <span class="op">=</span> <span class="va">x_explain</span>,</span>
<span>  x_train <span class="op">=</span> <span class="va">x_train</span>,</span>
<span>  approach <span class="op">=</span> <span class="st">"empirical"</span>,</span>
<span>  prediction_zero <span class="op">=</span> <span class="va">p0</span>,</span>
<span>  n_batches <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co">#| [=================================&gt;----------------------]  60% Estimating v(S)</span></span></code></pre></div>
<p><a id="compare"></a></p>
<p><br></p>
</div>
</div>
<div class="section level2">
<h2 id="comparison-to-lundberg-lees-implementation">Comparison to Lundberg &amp; Lee’s implementation<a class="anchor" aria-label="anchor" href="#comparison-to-lundberg-lees-implementation"></a>
</h2>
<p>As mentioned above, the original (independence assuming) Kernel SHAP
implementation can be approximated by setting a large <span class="math inline">\(\sigma\)</span> value using our empirical
approach. If we specify that the distances to <em>all</em> training
observations should be used (i.e. setting
<code>approach = "empirical"</code> and <code>empirical.eta = 1</code>
when using <code>explain</code>, we can approximate the original method
arbitrarily well by increasing <span class="math inline">\(\sigma\)</span>. For completeness of the
<code>shapr</code> package, we have also implemented a version of the
original method, which samples training observations independently with
respect to their distances to test observations (i.e. without the
large-<span class="math inline">\(\sigma\)</span> approximation). This
method is available by using <code>approach = "independence"</code> in
<code>explain</code>.</p>
<p>We have compared the results using these two variants with the
original implementation of <span class="citation">Lundberg and Lee
(2017)</span>, available through the Python library <a href="https://github.com/slundberg/shap" class="external-link"><code>shap</code></a>. As
above, we used the Boston housing data, trained via
<code>xgboost</code>. We specify that <em>all</em> training observations
should be used when explaining all of the 6 test observations. To run
the individual explanation method in the <code>shap</code> Python
library we use the <code>reticulate</code> <code>R</code>-package,
allowing Python code to run within <code>R</code>. As this requires
installation of Python package, the comparison code and results is not
included in this vignette, but can be found <a href="https://github.com/NorskRegnesentral/shapr/blob/master/inst/scripts/compare_shap_python.R" class="external-link">here</a>.
As indicated by the (commented out) results in the file above both
methods in our <code>R</code>-package give (up to numerical
approximation error) identical results to the original implementation in
the Python <code>shap</code> library.</p>
<p><br></p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-aas2019explaining" class="csl-entry">
Aas, Kjersti, Martin Jullum, and Anders Løland. 2021. <span>“Explaining
Individual Predictions When Features Are Dependent: More Accurate
Approximations to Shapley Values.”</span> <em><span>Artificial
Intelligence</span></em> 298.
</div>
<div id="ref-covert2020understanding" class="csl-entry">
Covert, Ian, Scott M Lundberg, and Su-In Lee. 2020. <span>“Understanding
Global Feature Contributions with Additive Importance Measures.”</span>
<em>Advances in Neural Information Processing Systems</em> 33: 17212–23.
</div>
<div id="ref-frye2020shapley" class="csl-entry">
Frye, Christopher, Damien de Mijolla, Tom Begley, Laurence Cowton, Megan
Stanley, and Ilya Feige. 2021. <span>“Shapley Explainability on the Data
Manifold.”</span> In <em>International Conference on Learning
Representations</em>.
</div>
<div id="ref-hothorn2006unbiased" class="csl-entry">
Hothorn, Torsten, Kurt Hornik, and Achim Zeileis. 2006. <span>“Unbiased
Recursive Partitioning: A Conditional Inference Framework.”</span>
<em>Journal of Computational and Graphical Statistics</em> 15 (3):
651–74.
</div>
<div id="ref-partykit_package" class="csl-entry">
Hothorn, Torsten, and Achim Zeileis. 2015. <span>“<span class="nocase">partykit</span>: A Modular Toolkit for Recursive
Partytioning in <span>R</span>.”</span> <em>Journal of Machine Learning
Research</em> 16: 3905–9.
</div>
<div id="ref-jullum2021efficient" class="csl-entry">
Jullum, Martin, Annabelle Redelmeier, and Kjersti Aas. 2021.
<span>“Efficient and Simple Prediction Explanations with groupShapley: A
Practical Perspective.”</span> In <em>Proceedings of the 2nd Italian
Workshop on Explainable Artificial Intelligence</em>, 28–43. CEUR
Workshop Proceedings.
</div>
<div id="ref-lundberg2017unified" class="csl-entry">
Lundberg, Scott M, and Su-In Lee. 2017. <span>“A Unified Approach to
Interpreting Model Predictions.”</span> In <em>Advances in Neural
Information Processing Systems</em>, 4765–74.
</div>
<div id="ref-olsen2022using" class="csl-entry">
Olsen, Lars Henry Berge, Ingrid Kristine Glad, Martin Jullum, and
Kjersti Aas. 2022. <span>“Using Shapley Values and Variational
Autoencoders to Explain Predictive Models with Dependent Mixed
Features.”</span> <em>Journal of Machine Learning Research</em> 23
(213): 1–51.
</div>
<div id="ref-olsen2023comparative" class="csl-entry">
———. 2023. <span>“A Comparative Study of Methods for Estimating
Conditional Shapley Values and When to Use Them.”</span> <em>arXiv
Preprint arXiv:2305.09536</em>.
</div>
<div id="ref-redelmeier2020explaining" class="csl-entry">
Redelmeier, Annabelle, Martin Jullum, and Kjersti Aas. 2020.
<span>“Explaining Predictive Models with Mixed Features Using Shapley
Values and Conditional Inference Trees.”</span> In <em>International
Cross-Domain Conference for Machine Learning and Knowledge
Extraction</em>, 117–37. Springer.
</div>
<div id="ref-rosenblatt1956" class="csl-entry">
Rosenblatt, Murray. 1956. <span>“<span class="nocase">Remarks on Some
Nonparametric Estimates of a Density Function</span>.”</span>
<em><span>The Annals of Mathematical Statistics</span></em> 27: 832–37.
</div>
<div id="ref-Shapley53" class="csl-entry">
Shapley, Lloyd S. 1953. <span>“<span class="nocase">A Value for N-Person
Games</span>.”</span> <em><span>Contributions to the Theory of
Games</span></em> 2: 307–17.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Nikolai Sellereite, Martin Jullum, Annabelle Redelmeier, Jon Lachmann, Norsk Regnesentral.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
