---
title: "Asymmetric and causal Shapley value explanations"
author: "Lars Henry Berge Olsen"
output:
  rmarkdown::html_vignette:
    toc: true
    fig_caption: yes
bibliography: ../inst/REFERENCES.bib
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteIndexEntry{Asymmetric and causal Shapley value explanations}
  %\VignetteEngine{knitr::rmarkdown}
editor_options:
  markdown:
    wrap: 72
    toc: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.cap = "",
  fig.width = 7,
  fig.height = 5,
  fig.path = "figure_asymmetric_causal/", # Ensure that figures are saved in the right folder (build vignette manually)
  cache.path = "cache_asymmetric_causal/", # Ensure that cached objects are saved in the right folder
  warning = FALSE,
  message = TRUE
)
```


# Overview of the vignette {#Vignette}

This vignette elaborates and demonstrates the asymmetric and 
causal Shapley value frameworks introduced by @frye2020asymmetric
and @heskes2020causal, respectively. We also consider the marginal
and conditional Shapley value frameworks, see @lundberg2017unified
and @aas2019explaining, respectively. We demonstrate the frameworks
on the [bike Sharing](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset.zip)
dataset from the UCI Machine Learning Repository. The setup is
based on the `CauSHAPley` package, which is is the 
[code supplement](https://proceedings.neurips.cc/paper/2020/hash/32e54441e6382a7fbacbbbaf3c450059-Abstract.html) 
to the @heskes2020causal paper. Note the `CauSHAPley` package was based
on an old version of `shapr` and was restricted to the `gaussian` approach.
We have extended the causal Shapley value framework to work for all
Monte Carlo-based approaches, while the asymmetric Shapley value framework
also works for the regression-based approaches. 
Our generalization is of uttermost importance, as many real-world data sets
are from the Gaussian distribution.




# Asymmetric conditional Shapley values {#AsymSV}

Asymmetric (condtional) Shapley values were proposed by @frye2020asymmetric as
a way to incorporate causal knowledge in the real world by restricting
the possible permutations of the features when computing the
Shapley values to those consistent with a (partial) causal ordering.
See the figure below for schematic overview of the causal ordering
we are going to use in the examples in this vignette.

That is, instead of considering the $2^M$ possible coalitions,
where $M$ is the number of features, asymmetric Shapley values only
consider the subset of coalitions which respects the causal ordering.
Meaning that if the ordering specifies that feature $X_1$ is the 
ancestor of $X_2$, then asymmetric Shapley values skips the coalitions
where $X_2$ is included but $X_1$ is \textit{not} included. 

We can use all approaches in \texttt{shapr}, both Monte Carlo-based and
regression based methods, to compute the asymmetric Shapley values.
This is because the asymmetric Shapley value framework does not change
how we compute the contribution functions $v(S)$, but rather which of
the coalitions $S$ that are used to compute the Shapley value explanations.

Instead of the number of coalitions being $O(2^M)$, we now get
$O(2^{C_{largest}})$, where $C_{largest}$ is the number of features in
the largest component in the causal ordering. 

Furthermore, asymmetric Shapley values supports groups of features, but
then the causal ordering must be given on the group level instead of the
individual features. The asymmetric Shapley value framework also supports
sampling of combinations/coalitions where the sampling is done from the
set of combinations that respects the causal ordering.

Finally, we want make a remark that asymmetric conditional Shapley are
equivalent to asymmetric causal Shapley values (see below) when we only
use the combinations respecting the causal ordering and assuming that all
dependencies within chain components are induced by mutual interactions.


```{r asymmetric_ordering, echo=FALSE, fig.cap="Schematic overview of the causal ordering used in this vignette.", fig.align='center', out.width = '50%'}
knitr::include_graphics("figure_asymmetric_causal/Asymmetric_ordering.png")
```


# Causal Shapley values {#CausSV}

Causal Shapley values were proposed by @heskes2020causal as a way
to explain the total effect of features on the prediction, taking
into account their causal relationships, by adapting the sampling
procedure in `shapr`. More precisely, they propose to employ Pearlâ€™s
do-calculus to to circumvent the independence assumption, made by
@lundberg2017unified, without sacrificing any of their desirable
properties of the Shapley value framework. The causal Shapley value
explanation framework can also separate the the contribution of direct
and indirect effects, which makes them principally different from
marginal and conditional Shapley values. They also provide a more 
direct and robust way to incorporate causal knowledge, compared to
asymmetric Shapley values.

To compute causal Shapley values, we have to specify a (partial) causal
ordering and make an assumption about the confounding in each component.
Together, they form a causal chain graph which has directed and undirected
edges. All features that are treated on an equal footing are linked
together with undirected edges and become part of the same chain component.
Edges between chain components are directed and represent causal relationships.
In the figure below, we have the same causal ordering as above, but we
have in addition made the assumption that we have confounding in the 
second component, but no confounding in the first and third components.
This allows us to correctly distinguishes between dependencies that are
due to confounding and mutual interactions. That is, in the figure,
the dependencies in chain component $\tau_2$ are assumed to be the result
of a common confounder, and those in $\tau_3$ of mutual interactions, while
we have no mutual interactions in $\tau_1$ as it is a singleton.

Computing the effect of an intervention depends on how we interpret the
generative process that lead to the feature dependencies within each component.
If they are the result of marginalizing out a common confounder,
then intervention on a particular feature will break the dependency
with the other features, and we denote the set of these chain components 
by $\mathcal{T}_{\text{confounding}}$. For the components with mutual
feature interactions, setting the value of a feature does affect the
distribution of the variables within the same component. We denote
the set of these components by $\mathcal{T}_{\,\overline{\text{confounding}}}$.

@heskes2020causal described how any expectation by intervention needed
to compute the causal Shapley values can be translated to an expectation
by observation, by using the interventional formula for causal chain graphs:
\begin{align} 
\label{eq:do}
P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S})) 
= &
\prod_{\tau \in \mathcal{T}_{\,\text{confounding}}}
P(X_{\tau \cap \bar{\mathcal{S}}} \mid X_{\text{pa}(\tau) \cap \bar{\mathcal{S}}}, x_{\text{pa}(\tau) \cap \mathcal{S}}) \times \tag{1} \\
& \quad 
\prod_{\tau \in \mathcal{T}_{\,\overline{\text{confounding}}}}
P(X_{\tau \cap \bar{\mathcal{S}}} \mid X_{\text{pa}(\tau) \cap \bar{\mathcal{S}}}, x_{\text{pa}(\tau) \cap \mathcal{S}}, x_{\tau \cap \mathcal{S}}).
\end{align}
Here, any of the Monte Carlo-based approaches in `shapr` can be
used to to compute the observational expectations. The marginals
are estimated from the training data for all approaches except
`gaussian`, for which we use the marginals of the Gaussian
distribution instead.

For specific causal chain graphs, the causal Shapley value framework
simplifies to symmetric conditional, asymmetric conditional, and marginal
Shapley values, see Corollary 1 to 3 in the supplement of @heskes2020causal.



```{r pressure, echo=FALSE, fig.cap="A causal chain graph", out.width = '50%'}
knitr::include_graphics("figure_asymmetric_causal/causal_ordering.png")
```


# Marginal Shapley values {#MarginaSV}
Causal Shapley values are equivalent to marginal Shapley values when all $M$
features combined in a single component $\tau = \mathcal{M} = \{1,2,...,M\}$ and
all dependencies are induced by confounding. Then $\text{pa}(\tau) = \emptyset$, and 
$P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S}))$ in Equation (\ref{eq:do})
simplifies to $P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S})) = P(X_{\bar{\mathcal{S}}})$,
as specified in @lundberg2017unified.

The Monte Carlo samples for the marginals are generated by sampling from the
training data, except for the `gaussian` approach where we use the marginals
of the modeled multivariate Gaussian distribution. This means that for all
other approaches, this is the same as using the `independence` approach 
in the conditional Shapley value framework. 

# Symmetric conditioal Shapley values {#ConditionalSV}
Causal Shapley values are equivalent to symmetric conditional Shapley values when all $M$
features combined in a single component $\tau = \mathcal{M} = \{1,2,...,M\}$ and
all dependencies are induced by mutual interaction. Then $\text{pa}(\tau) = \emptyset$,
and $P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S}))$ in Equation
(\ref{eq:do}) simplifies to
$P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S})) = P(X_{\bar{\mathcal{S}}} \mid X_\mathcal{S} = x_\mathcal{S})$,
as specified in @aas2019explaining. Symmetric means that we consider all coalitions.



# Code example
## Overview
We demonstrate the frameworks on the [bike Sharing](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset.zip)
dataset from the UCI Machine Learning Repository.

In the table below, we highlight the Shapley value explanation frameworks introduced above
and how to access them by changing the arguments `asymmetric`, `ordering`, and `confounding` in `explain()`.
Note that symmetric conditional Shapley values are the default version, i.e., by default
`asymmetric = FALSE`, `ordering = NULL`, `confounding = NULL`.

| Framework          | Sampling               | Approaches           | `asymmetric` | `ordering`  | `confounding` |
|:-------------------|:-----------------------|:---------------------|:-------------|:------------|:--------------|
| Sym. Conditional   | $P(X_{\bar{\mathcal{S}}} \mid (X_\mathcal{S} = x_\mathcal{S})$    | All                  | `FALSE`      | `NULL`      | `NULL`        |
| Asym. Conditional  | $P(X_{\bar{\mathcal{S}}} \mid (X_\mathcal{S} = x_\mathcal{S})$    | All                  | `TRUE`       | `list(...)` | `NULL`        |
| Sym. Causal        | $P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S}))$ |  All MC-based        | `FALSE`      | `list(...)` | `c(...)`      |
| Asym. Causal       | $P(X_{\bar{\mathcal{S}}} \mid do(X_\mathcal{S} = x_\mathcal{S}))$ |  All MC-based        | `TRUE`       | `list(...)` | `c(...)`      |
| Sym. Marginal      | $P(X_{\bar{\mathcal{S}}})$                                        | `indep.`, `gaussian` | `FALSE`      | `NULL`      | `TRUE`        | 

 <! -- | Asym. Marginal     | $P(X_{\bar{\mathcal{S}}})$                                        | `indep.`, `gaussian` | `TRUE`       | `NULL`      | `TRUE`        | -->


## Code setup
First, we load the needed libraries.
```{r libraries}
library(xgboost)
library(shapr)
library(ggplot2)
library(GGally)

library(progressr) # Just to get progress
progressr::handlers("cli")
```

Second, we set up the training/explicand data, plot the data, and train an `xgboost` model.
```{r setup}
bike <- read.csv("../inst/extdata/day.csv")
# Difference in days, which takes DST into account
bike$trend <- as.numeric(difftime(bike$dteday, bike$dteday[1], units = "days"))
bike$cosyear <- cospi(bike$trend/365*2)
bike$sinyear <- sinpi(bike$trend/365*2)
# Unnormalize variables (see data set information in link above)
bike$temp <- bike$temp * (39 - (-8)) + (-8)
bike$atemp <- bike$atemp * (50 - (-16)) + (-16)
bike$windspeed <- 67 * bike$windspeed
bike$hum <- 100 * bike$hum

# Plot the data
ggplot(bike, aes(x = trend, y = cnt, color = temp)) +
  geom_point(size = 0.75) + scale_color_gradient(low = "blue", high = "red") +
  labs(colour = "temp") +
  xlab( "Days since 1 January 2011") + ylab("Number of bikes rented") +
  theme_minimal() +
  theme(legend.position = "right", legend.title = element_text(size = 10))

# Define the features and the response variable
x_var <- c("trend", "cosyear", "sinyear", "temp", "atemp", "windspeed", "hum")
y_var <- "cnt"

# NOTE: Encountered RNG reproducibility issues across different systems,
# Load the training-test split.
train_index <- readRDS("../inst/extdata/train_index.rds")

# Training data
x_train <- as.matrix(bike[train_index, x_var])
y_train_nc <- as.matrix(bike[train_index, y_var]) # not centered
y_train <- y_train_nc - mean(y_train_nc)

# Plot pairs plot
ggpairs(x_train)

# Test data
x_explain <- as.matrix(bike[-train_index, x_var])
y_explain_nc <- as.matrix(bike[-train_index, y_var]) # not centered
y_explain <- y_explain_nc - mean(y_train_nc)

# Get 6 explicands to plot the Shapley values of with a wide spread in their predicted outcome
n_index_x_explain = 6
index_x_explain = order(y_explain)[seq(1, length(y_explain), length.out = n_index_x_explain)]
y_explain[index_x_explain]

# Fit an XGBoost model to the training data
model <- xgboost(
  data = x_train,
  label = y_train,
  nround = 100,
  verbose = FALSE
)

# Save the phi0
prediction_zero <- mean(y_train)

# Look at the root mean squared error 
sqrt(mean((predict(model, x_explain) - y_explain)^2))
plot(predict(model, x_explain), y_explain)
```


We are going to use the `causal_ordering` and `confounding` illustrated in the figures above.
For `causal_ordering`, we can either provide the index of feature or the feature names.
Thus, the following two versions of `causal_ordering` will produce equivalent results.

```{r}
causal_ordering = list(1, c(2, 3), c(4:7))
causal_ordering = list("trend", c("cosyear", "sinyear"), c("temp", "atemp", "windspeed", "hum"))
confounding = c(FALSE, TRUE, FALSE)
```



## Symmetric conditional Shapley values (default)
We start by demonstrating how to compute symmetric conditional Shapley values.
This is the default version in `shapr` and there is no need to specify the arguments below.
We have done it for the sake of clarity. We use the `gaussian` approach.
```{r}
explanation_sym_con_gaussian <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "gaussian",
    prediction_zero = prediction_zero,
    asymmetric = FALSE, # Default value (TRUE will give the same as `causal_ordering = NULL`)
    causal_ordering = NULL, # Default value
    confounding = NULL, # Default value
      keep_samp_for_vS = TRUE
  )
})

# Look at the number of combinations considered
explanation_sym_con_gaussian$internal$parameters$n_combinations

# Look at the elapsed time
explanation_sym_con_gaussian$timing$timing_secs

# Plot a beeswarm plot of the Shapley values
plot(explanation_sym_con_gaussian, plot_type = "beeswarm")
```
We can also use regression-based approaches. 
```{r}
explanation_sym_con_xgboost <- progressr::with_progress({
 explain(
  model = model,
  x_explain = x_explain,
  x_train = x_train,
  prediction_zero = prediction_zero,
  approach = "regression_separate",
  regression.model = parsnip::boost_tree(engine = "xgboost", mode = "regression"),
    asymmetric = FALSE, # Default value (TRUE will give the same as `causal_ordering = NULL`)
    causal_ordering = NULL, # Default value
    confounding = NULL # Default value
)
})
# Look at the number of combinations considered
explanation_sym_con_xgboost$internal$parameters$n_combinations

# Look at the elapsed time
explanation_sym_con_xgboost$timing$timing_secs

# Plot a beeswarm plot of the Shapley values
plot(explanation_asym_con_xgboost, plot_type = "beeswarm")
```

```{r}
explanation_sym_con_xgboost_cv <- progressr::with_progress({
 explain(
  model = model,
  x_explain = x_explain,
  x_train = x_train,
  prediction_zero = prediction_zero,
  n_batches = 10,
  approach = "regression_separate",
  regression.model =
    parsnip::boost_tree(trees = hardhat::tune(), engine = "xgboost", mode = "regression"),
  regression.tune_values = expand.grid(trees = c(10, 15, 25, 50, 100)),
  regression.vfold_cv_para = list(v = 4),
    asymmetric = FALSE, # Default value (TRUE will give the same as `causal_ordering = NULL`)
    causal_ordering = NULL, # Default value
    confounding = NULL # Default value
)
})
# Look at the number of combinations considered
explanation_sym_con_xgboost_cv$internal$parameters$n_combinations

# Look at the elapsed time
explanation_sym_con_xgboost_cv$timing$timing_secs

# Plot a beeswarm plot of the Shapley values
plot(explanation_sym_con_xgboost_cv, plot_type = "beeswarm")
```




## Asymmetric conditional Shapley values
The we look at the asymmetric conditional Shapley values. To obtain these
types of Shapley values, we have to specify that `asymmetric = TRUE` and a
`causal_ordering`. We use `causal_ordering = list(1, c(2, 3), c(4:7))`, which
implies that we consider $20$ combinations (including empty and grand coalition)
instead of all 128 coalitions.

```{r}
explanation_asym_con_gaussian <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    prediction_zero = prediction_zero,
    approach = "gaussian",
    asymmetric = TRUE,
    causal_ordering = causal_ordering,
    confounding = NULL # Default value
  )
})
# Look at the number of combinations considered. Only 20 instead of 128.
explanation_asym_con_gaussian$internal$parameters$n_combinations_causal_max

# Here we can see the 20 combinations that respects the causal ordering
explanation_asym_con_gaussian$internal$objects$legit_causal_combinations

# Look at the elapsed time
explanation_asym_con_gaussian$timing$timing_secs

# Plot a beeswarm plot of the Shapley values
plot(explanation_asym_con_gaussian, plot_type = "beeswarm")
```
We can also use a regression-based approach to compute asymmetirc conditional Shapley values.

```{r}
explanation_asym_con_xgboost <- progressr::with_progress({
 explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    prediction_zero = prediction_zero,
    approach = "regression_separate",
    regression.model = parsnip::boost_tree(engine = "xgboost", mode = "regression"),
    asymmetric = TRUE,
    causal_ordering = causal_ordering,
    confounding = NULL # Default value
)
})
# Look at the number of combinations considered. Only 20 instead of 128.
explanation_asym_con_xgboost$internal$parameters$n_combinations_causal_max

# Look at the elapsed time
explanation_asym_con_xgboost$timing$timing_secs

# Plot a beeswarm plot of the Shapley values
plot(explanation_asym_con_xgboost, plot_type = "beeswarm")
```


## Symmetric marginal Shapley values
For marginal Shapley values, we can only consider the symmetric version as we must set
`causal_ordering = list(1:7)` (or `NULL`) and `confounding = TRUE`. Setting `asymmetric = TRUE`
will have no effect, as the causal ordering consists of only a single component containing all features,
i.e., all coalitions respect the causal ordering. As stated above, `shapr` will generate the 
Monte Carlos samples from the marginals either from the Gaussian marginals if `approach = "gaussian"`, 
while for all other Monte Carlo approaches the marginals are estimated from the training data, i.e.,
assuming feature independence. Furthermore, we also obtain marginal Shapley values by using the
conditional Shapley value framework with the `independence` approach. However, note that there will
be a minuscule difference in the produced Shapley values due to different sampling setups/orders.

```{r}
# Here we sample from the estimated Gaussian marginals
explanation_sym_marg_gaussian <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "gaussian",
    prediction_zero = prediction_zero,
    asymmetric = FALSE, 
    causal_ordering = list(1:7), 
    confounding = TRUE 
  )
})

# Here we sample from the marginals of the training data
explanation_sym_marg_any_other_approach <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "independence",
    prediction_zero = prediction_zero,
    asymmetric = FALSE, 
    causal_ordering = list(1:7), 
    confounding = TRUE 
  )
})

# Here we use the conditional Shapley value framework with the `independence` approach
explanation_sym_marg_independence <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "independence",
    prediction_zero = prediction_zero
  )
})

# Plot beeswarms plot of the Shapley values. All three are very similar.
plot(explanation_sym_marg_gaussian, plot_type = "beeswarm")
plot(explanation_sym_marg_any_other_approach, plot_type = "beeswarm")
plot(explanation_sym_marg_independence, plot_type = "beeswarm")
sina_plot(explanation_sym_marg_independence)
```





## Causal Shapley values
To compute (symmetric/asymmetric) causal Shapley values, we have to provide
the `causal_ordering` and `confounding` objects. We set them to be 
`causal_ordering = list(1, 2:3, 4:7)` and `confounding = c(FALSE, TRUE, FALSE)`.

The causal framework takes longer than the other framework, as generating the 

For example, for $\mathcal{S} = {2}$, we must generate $X_1,X_3,X_4,X_5,X_6,X_7 \mid X_2$. However, we cannot do this
directly due to the `causal_ordering` and `confounding` specified above. To generate the Monte Carlo samples, we have
to follow a chain of sampling steps. More precisely, we first need to generate $X_1$ from the marginal,
then $X_3 \mid X_1$, and finally $X_4,X_5,X_6,X_7 \mid X_1,X_2,X_3$. The latter two steps are done by 
using the provided `approach` to model the conditional distributions.

The `internal$objects$S_causal_steps_strings` object contains the sampling steps needed for the different combinations.

### Symmetric 
```{r}
explanation_sym_cau_gaussian <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "gaussian",
    prediction_zero = prediction_zero,
    asymmetric = FALSE, 
    causal_ordering = list(1, 2:3, 4:7),
    confounding = c(FALSE, TRUE, FALSE),
    keep_samp_for_vS = TRUE
  )
})

# Look at the sampling steps for the third combination (S = {2})
explanation_sym_cau_gaussian$internal$objects$S_causal_steps_strings$id_combination_3

# Use the copula approach
explanation_sym_cau_copula <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "copula",
    prediction_zero = prediction_zero,
    asymmetric = FALSE, 
    causal_ordering = list(1, 2:3, 4:7),
    confounding = c(FALSE, TRUE, FALSE),
    keep_samp_for_vS = TRUE
  )
})

# Plot beeswarms plot of the Shapley values. Both are very similar.
plot(explanation_sym_cau_gaussian, plot_type = "beeswarm")
plot(explanation_sym_cau_copula, plot_type = "beeswarm")
```



### Asymmetric
We now turn to asymmetric causal Shapley values. That is, we only use the combinations
that respects the causal ordering. Thus, the computations are faster as the number of
combinations are reduced. We 

```{r}
explanation_asym_cau_gaussian <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "gaussian",
    prediction_zero = prediction_zero,
    asymmetric = TRUE, 
    causal_ordering = list(1, 2:3, 4:7),
    confounding = c(FALSE, TRUE, FALSE),
    keep_samp_for_vS = TRUE
  )
})

# Use the copula approach
explanation_asym_cau_copula <- progressr::with_progress({
  explain(
    model = model,
    x_train = x_train,
    x_explain = x_explain,
    approach = "copula",
    prediction_zero = prediction_zero,
    asymmetric = TRUE, 
    causal_ordering = list(1, 2:3, 4:7),
    confounding = c(FALSE, TRUE, FALSE),
    keep_samp_for_vS = TRUE
  )
})

# Plot beeswarms plot of the Shapley values. Both are very similar.
plot(explanation_asym_cau_gaussian, plot_type = "beeswarm")
plot(explanation_asym_cau_copula, plot_type = "beeswarm")

# Plot the Shapley values 
plot_SV_several_approaches(list(gaussian = explanation_asym_cau_gaussian,
                                copula = explanation_asym_cau_copula),
                           index_explicands = index_x_explain,
                           index_explicands_sort = FALSE)

```


We can also use the other Monte Carlo-based approaches.
We demonstrate for `ctree`. Note that `independence`, 


## Compare them all
Plot the Shapley values for the six explicands. We see that the different 
frameworks provide different explanations. The largest difference are between
whether we use the symmetric or asymmetric version,

```{r}
# Plot the Shapley values 
plot_SV_several_approaches(
  list(
    symmetric_marginal = explanation_sym_marg_gaussian,
    symmetric_conditional = explanation_sym_con_gaussian,
    symmetric_causal = explanation_sym_cau_gaussian,
    asymmetric_conditional = explanation_asym_con_gaussian,
    asymmetric_causal = explanation_asym_cau_gaussian),
  index_explicands = index_x_explain,
  index_explicands_sort = FALSE)
```



## Groups of features
In this section, we demonstrate that we can compute marginal, asymmetric 
conditional, and symmetric/asymmetric Shapley values for groups of features, too.
The causal ordering has then has to specified on the group order and not on the 
feature level.

In the pairs plot above (and below), we see that it can be natural to group the
features `temp` and `atemp` due to their similarity/correlation. 

```{r}
# It makes sense to group the "temp" and "atemp" due to their high correlation
cor(x_train[,4], x_train[,5])
plot(x_train[,4], x_train[,5])
```

We then set up the groups and update the causal ordering to be on the group level.
```{r}
group_list <- list(
  trend = "trend",
  cosyear = "cosyear",
  sinyear = "sinyear",
  temp_group = c("temp", "atemp"),
  windspeed = "windspeed",
  hum = "hum")

causal_ordering_group = list("trend", c("cosyear", "sinyear"), c("temp_group", "windspeed", "hum"))
```


We illustrate 
```{r}
explanation_asym_cau_gaussian_group <-
    progressr::with_progress({
      explain(
        model = model,
        x_train = x_train,
        x_explain = x_explain,
        approach = "gaussian",
        prediction_zero = prediction_zero,
        asymmetric = TRUE,
        causal_ordering = causal_ordering_group,
        confounding = confounding,
        group = group_list
      )
    })


index_x_explain

explanation_asym_cau_gaussian_group$internal$objects$X
sina_plot(explanation_asym_cau_gaussian_group)
plot(explanation_asym_cau_gaussian_group, index_x_explain = 1:6)
```





## Implementation details

The marginal Shapley value explanation framework can be extended to
support modeling the marginal distributions using the `copula` and
`vaeac` approaches as both of these methods support unconditional sampling.

The `shapr` package is built to estimate conditional Shapley values, thus,
it parallelize over the combinations. This makes perfect sense for said
framework as each batch of combinations are independent of other batches,
which means that it is easy to parallelize. Furthermore, by using many
batches we drastically reduce the memory usage as `shapr` does not need
to store the Monte Carlo samples for all combinations. 

This setup is not optimal for the causal Shapley value framework as the
chains of sampling steps for two coalition $\mathcal{S}$ and $\mathcal{S}^*$
can contain many of the same steps. Ideally, each unique sampling step
should only be modeled once to save computation times, but, some of the
sampling steps will occur in many of the chains. Thus, we would then have
to store the Monte Carlo samples for all combinations where this sampling
step was included, and we can therefor run into memory consumption problems.
Thus, in the current implementation, we treat each coalition $\mathcal{S}$
independent and remodel the needed sampling steps for each combination.

Furthermore, in the conditional Shapley value framework, we have that
$\bar{\mathcal{S}} = \mathcal{M} \backslash \mathcal{S}$, thus `shapr`
will by default generate Monte Carlo samples for all features not in
$\mathcal{S}$. For the causal Shapley value framework, this is not the
case, i.e., $\bar{\mathcal{S}} \neq \mathcal{M} \backslash \mathcal{S}$ 
in general. To reuse the code, we generate Monte Carlo samples for all
features not in $\mathcal{S}$, but only keep the samples for the features
in $\bar{\mathcal{S}}$. To speed up `shapr` further, one could rewrite 
all the approaches to support that $\bar{\mathcal{S}}$ could not be
the complement of $\mathcal{S}$.

In the code below, we see the unique combinations/set of features to condition
on to generate the Monte Carlo samples for all combinations and the number of 
times that set of conditional features is needed in the symmetric causal Shapley
value framework for the set up above. We see that most of the conditional
distributions will now be remodeled eights times. For the `gaussian` approach,
which is very fast to estimate the conditional distributions, this does not 
have a major impact on the time. However, for, e.g., the `ctree` approach which
is much slower, this will take a significant amount of extra time.
```{r}
S_causal_steps = explanation_sym_cau_gaussian$internal$objects$S_causal_steps
S_causal_unlist = do.call(c, unlist(S_causal_steps, recursive=FALSE))
S_causal_steps_freq = S_causal_unlist[grepl("\\.S(?!bar)", names(S_causal_unlist), perl = TRUE)]
S_causal_steps_freq <- S_causal_steps_freq[!sapply(S_causal_steps_freq, is.null)] # Remove NULLs
S_causal_steps_freq <- S_causal_steps_freq[sapply(S_causal_steps_freq, length) > 0] # Remove extra integer(0)
table(sapply(S_causal_steps_freq, paste0, collapse = ","))
```

The `independence`, `empirical`, and `ctree` produce weighted Monte Carlo samples.
That means that they do not necessarily generate `n_samples`. To ensure `n_samples`, 
we sample `n_samples` samples using weighted sampling with replacements where
the weights are the weights returned by the approaches. 

# References
