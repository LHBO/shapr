% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/approach.R, R/approach_categorical.R,
%   R/approach_copula.R, R/approach_ctree.R, R/approach_empirical.R,
%   R/approach_gaussian.R, R/approach_independence.R, R/approach_timeseries.R,
%   R/approach_vaeac.R
\name{setup_approach}
\alias{setup_approach}
\alias{setup_approach.categorical}
\alias{setup_approach.copula}
\alias{setup_approach.ctree}
\alias{setup_approach.empirical}
\alias{setup_approach.gaussian}
\alias{setup_approach.independence}
\alias{setup_approach.timeseries}
\alias{setup_approach.vaeac}
\title{Set up the framework chosen approach}
\usage{
setup_approach(internal, ...)

\method{setup_approach}{categorical}(
  internal,
  categorical.joint_prob_dt = NULL,
  categorical.epsilon = 0.001,
  ...
)

\method{setup_approach}{copula}(internal, ...)

\method{setup_approach}{ctree}(
  internal,
  ctree.mincriterion = 0.95,
  ctree.minsplit = 20,
  ctree.minbucket = 7,
  ctree.sample = TRUE,
  ...
)

\method{setup_approach}{empirical}(
  internal,
  empirical.type = "fixed_sigma",
  empirical.eta = 0.95,
  empirical.fixed_sigma = 0.1,
  empirical.n_samples_aicc = 1000,
  empirical.eval_max_aicc = 20,
  empirical.start_aicc = 0.1,
  empirical.cov_mat = NULL,
  model = NULL,
  predict_model = NULL,
  ...
)

\method{setup_approach}{gaussian}(internal, gaussian.mu = NULL, gaussian.cov_mat = NULL, ...)

\method{setup_approach}{independence}(internal, ...)

\method{setup_approach}{timeseries}(
  internal,
  timeseries.fixed_sigma_vec = 2,
  timeseries.bounds = c(NULL, NULL),
  ...
)

\method{setup_approach}{vaeac}(
  internal,
  vaeac.model_description = NULL,
  vaeac.folder_to_save_model = NULL,
  vaeac.use_cuda = FALSE,
  vaeac.num_different_vaeac_initiate = 10,
  vaeac.epochs_initiation_phase = 2,
  vaeac.epochs = 200,
  vaeac.save_VAEAC_every_nth_epoch = NULL,
  vaeac.validation_ratio = 0.25,
  vaeac.validation_iwae_num_samples = 25,
  vaeac.depth = 3,
  vaeac.width = 32,
  vaeac.latent_dim = 8,
  vaeac.lr = 0.001,
  vaeac.batch_size = 64,
  vaeac.running_avg_num_values = 5,
  vaeac.activation_function = torch::nn_relu,
  vaeac.use_skip_connections = TRUE,
  vaeac.use_skip_connections_between_masked_encoder_and_decoder = TRUE,
  vaeac.use_batch_normalization = FALSE,
  vaeac.paired_sampling = TRUE,
  vaeac.masking_ratio = 0.5,
  vaeac.mask_generator_only_these_coalitions = NULL,
  vaeac.mask_generator_only_these_coalitions_probabilities = NULL,
  vaeac.sigma_mu = 10000,
  vaeac.sigma_sigma = 1e-04,
  vaeac.save_data = FALSE,
  vaeac.transform_all_continuous_features = FALSE,
  vaeac.verbose = FALSE,
  vaeac.seed = 1996,
  ...
)
}
\arguments{
\item{internal}{Not used.}

\item{...}{\code{approach}-specific arguments. See below.}

\item{categorical.joint_prob_dt}{Data.table. (Optional)
Containing the joint probability distribution for each combination of feature
values.
\code{NULL} means it is estimated from the \code{x_train} and \code{x_explain}.}

\item{categorical.epsilon}{Numeric value. (Optional)
If \code{joint_probability_dt} is not supplied, probabilities/frequencies are
estimated using \code{x_train}. If certain observations occur in \code{x_train} and NOT in \code{x_explain},
then epsilon is used as the proportion of times that these observations occurs in the training data.
In theory, this proportion should be zero, but this causes an error later in the Shapley computation.}

\item{ctree.mincriterion}{Numeric scalar or vector. (default = 0.95)
Either a scalar or vector of length equal to the number of features in the model.
Value is equal to 1 - \eqn{\alpha} where \eqn{\alpha} is the nominal level of the conditional independence tests.
If it is a vector, this indicates which value to use when conditioning on various numbers of features.}

\item{ctree.minsplit}{Numeric scalar. (default = 20)
Determines minimum value that the sum of the left and right daughter nodes required for a split.}

\item{ctree.minbucket}{Numeric scalar. (default = 7)
Determines the minimum sum of weights in a terminal node required for a split}

\item{ctree.sample}{Boolean. (default = TRUE)
If TRUE, then the method always samples \code{n_samples} observations from the leaf nodes (with replacement).
If FALSE and the number of observations in the leaf node is less than \code{n_samples},
the method will take all observations in the leaf.
If FALSE and the number of observations in the leaf node is more than \code{n_samples},
the method will sample \code{n_samples} observations (with replacement).
This means that there will always be sampling in the leaf unless
\code{sample} = FALSE AND the number of obs in the node is less than \code{n_samples}.}

\item{empirical.type}{Character. (default = \code{"fixed_sigma"})
Should be equal to either \code{"independence"},\code{"fixed_sigma"}, \code{"AICc_each_k"} \code{"AICc_full"}.
TODO: Describe better what the methods do here.}

\item{empirical.eta}{Numeric. (default = 0.95)
Needs to be \verb{0 < eta <= 1}.
Represents the minimum proportion of the total empirical weight that data samples should use.
If e.g. \code{eta = .8} we will choose the \code{K} samples with the largest weight so that the sum of the weights
accounts for 80\\% of the total weight.
\code{eta} is the \eqn{\eta} parameter in equation (15) of Aas et al (2021).}

\item{empirical.fixed_sigma}{Positive numeric scalar. (default = 0.1)
Represents the kernel bandwidth in the distance computation used when conditioning on all different combinations.
Only used when \code{empirical.type = "fixed_sigma"}}

\item{empirical.n_samples_aicc}{Positive integer. (default = 1000)
Number of samples to consider in AICc optimization.
Only used for \code{empirical.type} is either \code{"AICc_each_k"} or \code{"AICc_full"}.}

\item{empirical.eval_max_aicc}{Positive integer. (default = 20)
Maximum number of iterations when optimizing the AICc.
Only used for \code{empirical.type} is either \code{"AICc_each_k"} or \code{"AICc_full"}.}

\item{empirical.start_aicc}{Numeric. (default = 0.1)
Start value of the \code{sigma} parameter when optimizing the AICc.
Only used for \code{empirical.type} is either \code{"AICc_each_k"} or \code{"AICc_full"}.}

\item{empirical.cov_mat}{Numeric matrix. (Optional, default = NULL)
Containing the covariance matrix of the data generating distribution used to define the Mahalanobis distance.
\code{NULL} means it is estimated from \code{x_train}.}

\item{model}{Objects.
The model object that ought to be explained.
See the documentation of \code{\link[=explain]{explain()}} for details.}

\item{predict_model}{Function.
The prediction function used when \code{model} is not natively supported.
See the documentation of \code{\link[=explain]{explain()}} for details.}

\item{gaussian.mu}{Numeric vector. (Optional)
Containing the mean of the data generating distribution.
\code{NULL} means it is estimated from the \code{x_train}.}

\item{gaussian.cov_mat}{Numeric matrix. (Optional)
Containing the covariance matrix of the data generating distribution.
\code{NULL} means it is estimated from the \code{x_train}.}

\item{timeseries.fixed_sigma_vec}{Numeric. (Default = 2)
Represents the kernel bandwidth in the distance computation. TODO: What length should it have? 1?}

\item{timeseries.bounds}{Numeric vector of length two. (Default = c(NULL, NULL))
If one or both of these bounds are not NULL, we restrict the sampled time series to be
between these bounds.
This is useful if the underlying time series are scaled between 0 and 1, for example.}

\item{vaeac.model_description}{String containing, e.g., the name of the data distribution or additional parameter information. Used in the save name of the fitted model.}

\item{vaeac.folder_to_save_model}{String specifying a path to a folder where the function is to save the fitted VAEAC model.}

\item{vaeac.use_cuda}{Boolean. If we are to use cuda (GPU) if available. NOT TESTED!}

\item{vaeac.num_different_vaeac_initiate}{Integer. The number of different VAEAC models to initiate in the start. Pick the best performing one after \code{epochs_initiation_phase } and continue training that one.}

\item{vaeac.epochs_initiation_phase}{Integer. The number of epochs to run each of the \code{num_different_vaeac_initiate} VAEAC models before only continuing training the best one.}

\item{vaeac.epochs}{Integer. The number of epochs to train the final VAEAC model. This includes \code{epochs_initiation_phase}.}

\item{vaeac.save_VAEAC_every_nth_epoch}{Integer. If we are to save the VAEAC model after every nth epoch.}

\item{vaeac.validation_ratio}{Scalar between 0 and 1 indicating the ratio of instances from data which will be used as validation data.}

\item{vaeac.validation_iwae_num_samples}{Integer. The number of samples used to compute the IWAE when validating the VAEAC model on the validation data.}

\item{vaeac.depth}{Integer. The number of hidden layers in the neural networks of the masked encoder, full encoder, and decoder.}

\item{vaeac.width}{Integer. The number of neurons in each hidden layer in the neural networks of the masked encoder, full encoder, and decoder.}

\item{vaeac.latent_dim}{Integer. The number of dimensions in the latent space.}

\item{vaeac.lr}{Numeric. The learning rate used in the ADAM optimizer.}

\item{vaeac.batch_size}{Integer. The number of samples to include in each batch.}

\item{vaeac.running_avg_num_values}{Integer. How many of the previous values to include when we compute the running means.}

\item{vaeac.activation_function}{An torch::nn_module representing an activation function. E.g., torch::nn_relu, torch::nn_leaky_relu, torch::nn_selu, torch::nn_sigmoid.}

\item{vaeac.use_skip_connections}{Boolean. If we are to use skip connections in each layer. If true, then we add the input to the outcome of each hidden layer, so the output becomes X + activation(WX + b). I.e., identity skip connection.}

\item{vaeac.use_skip_connections_between_masked_encoder_and_decoder}{Boolean. If we are to apply concatenate skip connections between the layers in the masked encoder and decoder.}

\item{vaeac.use_batch_normalization}{Boolean. If we are to use batch normalization after the activation function. Note that if \code{use_skip_connections} is TRUE, then the normalization is
done after the adding from the skip connection. I.e, we batch normalize the whole quantity X + activation(WX + b).}

\item{vaeac.paired_sampling}{Boolean. If we are doing paired sampling. I.e., each batch contains two versions of the same training observation,
but where the first one is masked by S and the second one is masked by \bar{S}, the complement. See FastSHAP by Jethani et al (2022). Training becomes more stable, but slower due to non-optimal implementation.}

\item{vaeac.masking_ratio}{Probability of masking a feature in the MCAR mask generator. Default masking scheme which ensures that
VAEAC can do arbitrary conditioning. Is overruled if \code{mask_generator_only_these_coalitions} is specified.}

\item{vaeac.mask_generator_only_these_coalitions}{Matrix containing the different coalitions to learn.}

\item{vaeac.mask_generator_only_these_coalitions_probabilities}{Numerics containing the probabilities for sampling each mask in \code{mask_generator_only_these_coalitions}.
Array containing the probabilities for sampling the coalitions in \code{mask_generator_only_these_coalitions}.}

\item{vaeac.sigma_mu}{Numeric representing a hyperparameter in the normal-gamma prior used on the masked encoder, see Section 3.3.1 in Olsen et al. (2022).}

\item{vaeac.sigma_sigma}{Numeric representing a hyperparameter in the normal-gamma prior used on the masked encoder, see Section 3.3.1 in Olsen et al. (2022).}

\item{vaeac.save_data}{Boolean. If we are to save the data together with the model. Useful if one are to continue to train the model later.}

\item{vaeac.transform_all_continuous_features}{Boolean. If we are to log transform all continuous features before sending the data to VAEAC.
VAEAC creates unbounded values, so if the continuous features are strictly positive, as for Burr and Abalone data, it can be advantageous
to log-transform the data to unbounded form before using VAEAC. If TRUE, then \code{VAEAC_postprocess_data} will take the exp of the results
to get back to strictly positive values when using the VAEAC model to impute missing values.}

\item{vaeac.verbose}{Boolean. If we are to print the progress of the initialization of different VAEAC models, the training of the final VAEAC model, and summary of the training progress.}

\item{vaeac.seed}{Integer. Seed for reproducibility.}
}
\description{
The different choices of \code{approach} takes different (optional) parameters,
which are forwarded from \code{\link[=explain]{explain()}}.
}
